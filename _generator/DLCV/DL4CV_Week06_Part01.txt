# DL4CV_Week06_Part01.pdf - Page 1

```markdown
# Deep Learning for Computer Vision

## Explaining CNNs: Visualization Methods

**Vineeth N Balasubramanian**

Department of Computer Science and Engineering
Indian Institute of Technology, Hyderabad

![IIT Hyderabad Logo](https://via.placeholder.com/150)

---

Vineeth N B (IIT-H) &sect;6.1 Explaining CNNs: Visualization Methods

---

### Introduction

In this section, we will discuss various methods for visualizing Convolutional Neural Networks (CNNs). Visualization techniques are essential for understanding the internal workings of CNNs and for debugging and improving their performance.

### Visualization Techniques

1. **Activation Maps**
   - Activation maps highlight the regions of an input image that most strongly activate a particular filter in a convolutional layer.
   - They are usually generated by overlaying the activation strengths on the original image.

    ```markdown
    ![Activation Map](https://via.placeholder.com/300)
    ```

2. **Class Activation Maps (CAMs)**
   - CAMs provide a spatial representation of which parts of the input image contribute most to a particular class prediction.
   - They are generated by combining the activations of the final convolutional layer with the weights of the fully connected layer.

    ```markdown
    ![Class Activation Map](https://via.placeholder.com/300)
    ```

3. **Grad-CAM (Gradient-weighted Class Activation Mapping)**
   - Grad-CAM is an extension of CAM that combines gradient information with the activation maps to provide more precise localization.
   - It helps in highlighting the important regions that contribute to the class prediction.

    ```markdown
    ![Grad-CAM](https://via.placeholder.com/300)
    ```

4. **Feature Visualization**
   - Feature visualization involves generating images that maximize the activation of specific filters in a convolutional layer.
   - This helps in understanding what features a particular filter is detecting.

    ```markdown
    ![Feature Visualization](https://via.placeholder.com/300)
    ```

### Applications of Visualization

- **Model Interpretation**: Visualization helps in interpreting the decision-making process of CNNs.
- **Debugging**: Identifying and correcting issues in the network by visualizing the intermediate outputs.
- **Model Improvement**: Providing insights for improving the architecture and training process of CNNs.

### Conclusion

Visualization methods are powerful tools for understanding and improving CNNs. They provide insights into the internal mechanisms of these models and help in making data-driven decisions for model enhancement.

---

Page 1 of 15
```

# DL4CV_Week06_Part01.pdf - Page 2

```markdown
# Acknowledgements

- Most of this lecture’s slides are based on **Lecture 13** of **CS231n: Convolutional Neural Networks for Visual Recognition** course taught by Fei-Fei Li and others at Stanford University.

- Some content (AlexNet CNN figures, etc) is also adapted from **Lecture 12** of **CS7015: Deep Learning** course taught by Mitesh Khapra at IIT Madras.

---

Vineeth N B (IIT-H) & sec 6.1 Explaining CNNs: Visualization Methods

2 / 15
```

# DL4CV_Week06_Part01.pdf - Page 3

```markdown
# Visualize Filters/Kernels (First Layer)

## AlexNet:

64 x 3 x 11 x 11

![AlexNet Filters](image_url)

---

![Diagram](diagram_url)

---

1 Krizhevsky, One weird trick for parallelizing convolutional neural networks, 2014

Vineeth N B (IIT-H) §6.1 Explaining CNNs: Visualization Methods

---

3 / 15
```

# DL4CV_Week06_Part01.pdf - Page 4

```markdown
# Visualize Filters/Kernels (First Layer)

![Filters/Kernels](image_url)

**AlexNet:**
- 64 x 3 x 11 x 11

![Closer Look (AlexNet)](image_url)

**A Closer Look (AlexNet)**
Fan et al. (arxiv:1904.05526)

---

[^1]: Krizhevsky, One weird trick for parallelizing convolutional neural networks, 2014

Vineeth N B (IIT-H) §6.1 Explaining CNNs: Visualization Methods

---

3 / 15
```

# DL4CV_Week06_Part01.pdf - Page 5

```markdown
# Visualize Filters/Kernels (First Layer)

## AlexNet:
### 64 x 3 x 11 x 11

### A Closer Look (AlexNet)

![AlexNet Filters](image_url)

Fan et al. (arxiv:1904.05526)

## ResNet-18:
### 64 x 3 x 7 x 7

![ResNet-18 Filters](image_url)

## ResNet-101:
### 64 x 3 x 7 x 7

![ResNet-101 Filters](image_url)

## DenseNet-121:
### 64 x 3 x 7 x 7

![DenseNet-121 Filters](image_url)

---

^ Krizhevsky, One weird trick for parallelizing convolutional neural networks, 2014

Vineeth N B (IIT-H)

§6.1 Explaining CNNs: Visualization Methods

---

Page: 3 / 15
```

Note: Placeholders for image URLs should be replaced with the actual URLs or paths to the images if available.

# DL4CV_Week06_Part01.pdf - Page 6

```markdown
# Visualize Filters/Kernels (First Layer)

- You can visualize the kernels of higher layers but it is just not interesting

![NPTEL Logo](image_url_placeholder)

Vineeth N B (IIT-H)

§6.1 Explaining CNNs: Visualization Methods

4 / 15
```

# DL4CV_Week06_Part01.pdf - Page 7

```markdown
# Visualize Filters/Kernels (First Layer)

- You can visualize the kernels of higher layers but it is just not interesting
- Input to higher layers is no more the images we know or understand, so becomes difficult to interpret the filters beyond the first layer

![Layer Weights](image_url)

**Weights:**

- **Layer 1 weights**
  - `16 x 3 x 7 x 7`

![Layer Weights](image_url)

**Weights:**

- **Layer 2 weights**
  - `20 x 16 x 7 x 7`

![Layer Weights](image_url)

**Weights:**

- **Layer 3 weights**
  - `20 x 20 x 7 x 7`

*Vineeth N B. (IIIT-H) §6.1 Explaining CNNs: Visualization Methods 4 / 15*
```

# DL4CV_Week06_Part01.pdf - Page 8

```markdown
# Visualize Filters/Kernels (First Layer)

## The Gabor-like filters fatigue

![Visualization Filters/Kernels](image_url)

Vineeth N B (IIIT-H) §6.1 Explaining CNNs: Visualization Methods

### Visualization Filters/Kernels (First Layer)

#### The Gabor-like filters fatigue

![Visualization](image_url)

- Vineeth N B (IIIT-H)
- §6.1 Explaining CNNs: Visualization Methods
- Slide 5/15
```

Note: Replace `image_url` with the actual URLs of the images if they are available. If the images cannot be captured via OCR, you will need to provide the URLs or describe the content of the images.

# DL4CV_Week06_Part01.pdf - Page 9

```markdown
# Visualize the Representation Space (Last Layer)

![Network Diagram](https://via.placeholder.com/600x400)

- **4096-dimensional feature vector for an image** (layer immediately before the classifier)
- **Run the network on many images, collect the feature vectors**

_Vineeth N B (IIIT-H)_

## §6.1 Explaining CNNs: Visualization Methods

6 / 15
```

# DL4CV_Week06_Part01.pdf - Page 10

```markdown
# Visualize the Representation Space (Last Layer)

- **Visualize the “space” of FC7 feature vectors by reducing dimensionality of vectors from 4096 to 2 dimensions**

![NPTEL Logo](image_url_placeholder)

Vineeth N B (IIT-H) §6.1 Explaining CNNs: Visualization Methods

Page 7 / 15
```

Note: Replace `image_url_placeholder` with the actual URL or file path of the logo image if available. If the image cannot be captured by OCR, you may need to manually insert it or provide the correct path.

# DL4CV_Week06_Part01.pdf - Page 11

```markdown
# Visualize the Representation Space (Last Layer)

- **Visualize the “space” of FC7 feature vectors by reducing dimensionality of vectors from 4096 to 2 dimensions**
  - Use any dimensionality reduction algorithm

![Diagram Placeholder](diagram-place-holder.png)

*Vineeth N B (IIT-H)*

*Section 6.1 Explaining CNNs: Visualization Methods*

*Page 7 / 15*
```

# DL4CV_Week06_Part01.pdf - Page 12

```markdown
# Visualize the Representation Space (Last Layer)

- Visualize the “space” of FC7 feature vectors by reducing dimensionality of vectors from 4096 to 2 dimensions
- Use any dimensionality reduction algorithm
- Simple algorithm: Principal Component Analysis (PCA)

![Diagram Placeholder](image_url)

**Vineeth N B (IIT-H)**

**§6.1 Explaining CNNs: Visualization Methods**

**7 / 15**
```

# DL4CV_Week06_Part01.pdf - Page 13

```markdown
# Visualize the Representation Space (Last Layer)

- Visualize the "space" of FC7 feature vectors by reducing dimensionality of vectors from 4096 to 2 dimensions
- Use any dimensionality reduction algorithm
  - Simple algorithm: **Principal Component Analysis (PCA)**
  - More complex: **t-SNE** (right)

![Visualization Example](image_url)

*van der Maaten and Hinton, Visualizing High-Dimensional Data Using t-SNE, Journal of Machine Learning Research, 2008*

*Vineeth N B (IIT-H)*

*§6.1 Explaining CNNs: Visualization Methods*

*7 / 15*
```

# DL4CV_Week06_Part01.pdf - Page 14

```markdown
# t-SNE Visualization

- Images that are nearby each other are also close in the CNN representation space, which implies that the CNN "sees" them as being very similar

![t-SNE Visualization](image-placeholder.png)

- Notice that the similarities are more often class-based and semantic, rather than pixel and color-based.

*Vineeth N B. (IIT-H) §6.1 Explaining CNNs: Visualization Methods*
```

# DL4CV_Week06_Part01.pdf - Page 15

```markdown
# Visualize Activations

**Conv5 feature map is 128 × 13 × 13; Visualize as 128 13 × 13 grayscale images**

![Visualization Example](image_url)

**Figure copyright: Jason Yosinski, 2014.**

Vineeth N B (IIT-H)

## §6.1 Explaining CNNs: Visualization Methods

```

# DL4CV_Week06_Part01.pdf - Page 16

```markdown
# Visualize Maximally Activating Image Patches

- Consider a CNN, and a single neuron in any of its intermediate layers

![Diagram of CNN architecture](image-url)

Vineeth N B (IIT-H) §6.1 Explaining CNNs: Visualization Methods

---

## Visualize Maximally Activating Image Patches

- Consider a CNN, and a single neuron in any of its intermediate layers

![Diagram of CNN architecture](image-url)

Vineeth N B (IIT-H) §6.1 Explaining CNNs: Visualization Methods

---

## Diagram Explanation

### CNN Architecture

1. **Input**: The input image is processed through several layers of the CNN.
2. **Convolutional Layers**: Multiple convolutional layers with different kernel sizes (e.g., 1x1, 3x3, 5x5) are shown.
3. **Max Pooling**: Max pooling layers are used to downsample the feature maps.
4. **Fully Connected (FC) Layers**: After the convolutional layers, the feature maps are flattened and passed through fully connected layers.
5. **Softmax Layer**: The final layer, softmax, outputs the classification probabilities.

### Visualizing Activating Patches

- Identify the image patches that maximally activate a specific neuron in the CNN.
- These patches help in understanding what features the neuron is sensitive to.
- Visualization methods can include heatmaps or highlight the specific regions contributing to the neuron's activation.

```

# DL4CV_Week06_Part01.pdf - Page 17

```markdown
# Visualize Maximally Activating Image Patches

- Consider a CNN, and a single neuron in any of its intermediate layers

![Diagram of a CNN](image_placeholder.png)

Vineeth N B (IIT-H) §6.1 Explaining CNNs: Visualization Methods 10 / 15
```

**Note**: Replace `image_placeholder.png` with the actual path or URL to the image if available. Ensure that any additional context or content is included as needed from the original material.

# DL4CV_Week06_Part01.pdf - Page 18

```markdown
# Visualize Maximally Activating Image Patches

- Consider a CNN, and a single neuron in any of its intermediate layers
- Feed images to the CNN and identify all images which cause that particular neuron to fire

![CNN Diagram](https://via.placeholder.com/600x300) 

- Input
- Convolution
- MaxPooling
- Convolution
- MaxPooling
- Convolution
- Flattening
- Fully Connected Layer
- Output

---

Vineeth N B (IIT-H) §6.1 Explaining CNNs: Visualization Methods 10 / 15
```

# DL4CV_Week06_Part01.pdf - Page 19

```markdown
# Visualize Maximally Activating Image Patches

- Consider a CNN, and a single neuron in any of its intermediate layers
- Feed images to the CNN and identify all images which cause that particular neuron to fire
- We can then easily trace back to the patch in the image which causes that neuron to fire

![Visualization Process](image_url)

_Image source: Vineeth N B (IIT-H) §6.1 Explaining CNNs: Visualization Methods_

## Visualization Process Diagram

### Steps

1. **Input**: Start with an image.
2. **Convolutional Layer**: Pass the image through a convolutional layer.
3. **MaxPooling Layer**: Apply max pooling.
4. **Clustering**: Apply clustering techniques to identify patterns.
5. **Additional Convolutions**: Further convolution operations are performed.
6. **MacroProbing**: Use macro probing to pinpoint significant features.
7. **Classification**: Classify the features to understand their significance.
8. **Output**: Generate the final visualization indicating the maximally activating patches.

## Example of a Visualization Process

![Example Visualization](example_image_url)

### Key Phases

- **Image Input**: The original image is fed into the CNN.
- **Neuron Activation**: Identify which neuron in which layer is activated.
- **Tracing Back**: Trace the path back to the image patch responsible for the neuron activation.
- **Visualization**: Visualize the patch that maximally activates the neuron.

### Mathematical Notations

\[
f(x) = \sum_{i=1}^{n} a_i x_i
\]

\[
g(x) = \max_{i=1}^{n} \left( w_i x_i \right)
\]

### Clustering and Classification

- **Clustering**: Group similar features together.
- **Classification**: Classify these features based on their activation patterns.

### Diagram Explanation

- **Layer Representation**: Each layer of the CNN is represented visually.
- **Activation Path**: The path from input to neuron activation is highlighted.
- **Maximally Activating Patches**: The patches that cause the neuron to fire are shown.

---

_Vineeth N B (IIT-H) §6.1 Explaining CNNs: Visualization Methods_

10 / 15
```

# DL4CV_Week06_Part01.pdf - Page 20

# Visualize Maximally Activating Image Patches

- Consider a CNN, and a single neuron in any of its intermediate layers
- Feed images to the CNN and identify all images which cause that particular neuron to fire
- We can then easily trace back to the patch in the image which causes that neuron to fire

![Visualization](image-url)

Vineeth N B (IIT-H) §6.1 Explaining CNNs: Visualization Methods 10 / 15

# DL4CV_Week06_Part01.pdf - Page 21

```markdown
# Visualize Maximally Activating Image Patches

- Consider a CNN, and a single neuron in any of its intermediate layers
- Feed images to the CNN and identify all images which cause that particular neuron to fire
- We can then easily trace back to the patch in the image which causes that neuron to fire

![Diagram](image_placeholder)

(Vineeth N B (IIT-H)) §6.1 Explaining CNNs: Visualization Methods 10 / 15
```

# DL4CV_Week06_Part01.pdf - Page 22

```markdown
# Visualize Maximally Activating Image Patches

- Repeating this for others neurons in the CNN shows us a pattern

![Maximally Activating Image Patches](image_url)

**Rich feature hierarchies for accurate object detection and semantic segmentation by Ross Girshick et al.**

*Vineeth N B (IIT-H) §6.1 Explaining CNNs: Visualization Methods*

---

11 / 15
```

# DL4CV_Week06_Part01.pdf - Page 23

```markdown
# Visualize Maximally Activating Image Patches

- Repeating this for others neurons in the CNN shows us a pattern

![Maximally Activating Image Patches](image_url)

Springenberg et al. "Striving for Simplicity: The All Convolutional Net". ICLR Workshop 2015. Figure copyright Jost Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, Martin Riedmiller

Vineeth N B (IIT-H) §6.1 Explaining CNNs: Visualization Methods 11 / 15
```

# DL4CV_Week06_Part01.pdf - Page 24

```markdown
# Occlusion Experiments

- Typically, we are interested in understanding which portions of an image are responsible for maximizing probability of a certain class

![Image Not Available](image-url)

*Zeiler and Fergus, Visualizing and Understanding Convolutional Networks, ECCV 2014*

*Vineeth N B (IIT-H)*

*6.1 Explaining CNNs: Visualization Methods*

---

Page: 12 / 15
```

# DL4CV_Week06_Part01.pdf - Page 25

```markdown
# Occlusion Experiments

- Typically, we are interested in understanding which portions of an image are responsible for maximizing the probability of a certain class.
- Occlude (gray out) different patches in the image (centered on each pixel), and see the effect on the predicted probability of the correct class → gives you a probability for each pixel.

![NPTEL Logo](https://via.placeholder.com/150)

## References
- Zeiler and Fergus, *Visualizing and Understanding Convolutional Networks*, ECCV 2014
- Vineeth N B (IIT-H)
- §6.1 Explaining CNNs: Visualization Methods

## Examples

### Input Image
![Example Image 1](https://via.placeholder.com/150) ![Example Image 2](https://via.placeholder.com/150) ![Example Image 3](https://via.placeholder.com/150)

### Probability of Correct Class
- ![Probability Heatmap 1](https://via.placeholder.com/150) 
- ![Probability Heatmap 2](https://via.placeholder.com/150) 
- ![Probability Heatmap 3](https://via.placeholder.com/150)
```

This markdown format provides a structured representation of the information extracted from the scientific text or slides, maintaining the accuracy and formatting of the original content.

# DL4CV_Week06_Part01.pdf - Page 26

```markdown
# Occlusion Experiments<sup>2</sup>

- **Typically, we are interested in understanding which portions of an image are responsible for maximizing probability of a certain class**
- **Occlude (gray out) different patches in the image (centered on each pixel), and see effect on predicted probability of the correct class** ⇒ **gives you a probability for each pixel**
  - For example, the first heat map (top) shows that occluding the face of the dog causes a maximum drop in the prediction probability

![Input image](image1.png) ![Probability of correct class](image2.png)

<sup>2</sup>Zeiler and Fergus, *Visualizing and Understanding Convolutional Networks*, ECCV 2014
Vineeth N B (IIT-M)
§6.1 Explaining CNNs: Visualization Methods

---

12 / 15
```

# DL4CV_Week06_Part01.pdf - Page 27

```markdown
# Occlusion Experiments

- Typically, we are interested in understanding which portions of an image are responsible for maximizing the probability of a certain class
- Occlude (gray out) different patches in the image (centered on each pixel), and see the effect on predicted probability of the correct class ⇒ gives you a probability for each pixel
- For example, the first heat map (top) shows that occluding the face of the dog causes a maximum drop in the prediction probability
- Similar observations for other images

![Input image](image-url)

![Probability of correct class](image-url)

---

*Source*: Zeiler and Fergus, "Visualizing and Understanding Convolutional Networks", ECCV 2014

*Vineeth N B (IIT-H)*

*86.1 Explaining CNNs: Visualization Methods*
```

# DL4CV_Week06_Part01.pdf - Page 28

```markdown
# Summary: ‘Don’t-disturb-the-model’ methods

![Diagram](image_url)

Vineeth N B (IIT-H) §6.1 Explaining CNNs: Visualization Methods

---

## Section Title

### Subsection 1

- **First bullet point**: Description or explanation.
- **Second bullet point**: Description or explanation.
- **Third bullet point**: Description or explanation.

### Subsection 2

#### Sub-subsection 2.1

- **First sub-bullet point**: Description or explanation.
- **Second sub-bullet point**: Description or explanation.

#### Sub-subsection 2.2

- **First sub-bullet point**: Description or explanation.
- **Second sub-bullet point**: Description or explanation.

### Equation Section

$$
E = mc^2
$$

$$
\int_{a}^{b} f(x) \, dx
$$

### Code Snippet

```python
def function_name(parameters):
    # Code description or implementation
    return result
```

### Table Example

| Column 1 | Column 2 | Column 3 |
| ------- | ------- | ------- |
| Cell 1  | Cell 2  | Cell 3  |
| Cell 4  | Cell 5  | Cell 6  |

### Image Description

![Alternative text](image_url)

### Bullet Points for Scientific Terms

- **Term 1**: Explanation of term.
- **Term 2**: Explanation of term.
- **Term 3**: Explanation of term.

### Mathematical Formulae

$$
y = mx + b
$$

$$
\sum_{i=1}^{n} i^2
$$

### Multi-lang Example

#### Français

- **Premier point**: Description.
- **Deuxième point**: Description.

#### Deutsch

- **Erster Punkt**: Beschreibung.
- **Zweiter Punkt**: Beschreibung.

---

Page 13 / 15
```

# DL4CV_Week06_Part01.pdf - Page 29

```markdown
# Summary: ‘Don’t-disturb-the-model’ methods

![Image Description](image-url)

## Vineeth N B (IIIT-H) &6.1 Explaining CNNs: Visualization Methods

### Slide: 13 / 15

This section is focused on the ‘Don’t-disturb-the-model’ methods, which aim to explain Convolutional Neural Networks (CNNs) without altering the model's structure or parameters.

### Key Visualization Techniques

1. **Input and Output Analysis**
   - **Input Layer:** The initial layer of the CNN where input data is fed.
   - **Output Layer:** The final layer where the network's predictions are made.
   - Intermediate layers are visualized to understand the transformation from input to output.

2. **Feature Maps**
   - Visualization of feature maps at various convolutional layers.
   - Helps in understanding the features learned by the network.

3. **Activation Maximization**
   - Techniques to visualize the most activating input patterns for specific neurons.
   - Useful for understanding what features the network is focusing on.

4. **Deconvolution**
   - Reversing the convolution process to generate input images from the activations.
   - This helps in visualizing which parts of the image are contributing to the activation of specific neurons.

### Diagram

A detailed diagram is shown, highlighting the different convolutional layers and the flow of data from input to output.

```markdown
# Summary: ‘Don’t-disturb-the-model’ methods

![Image Description](image-url)

## Vineeth N B (IIIT-H) &6.1 Explaining CNNs: Visualization Methods

### Slide: 13 / 15

This section is focused on the ‘Don’t-disturb-the-model’ methods, which aim to explain Convolutional Neural Networks (CNNs) without altering the model's structure or parameters.

### Key Visualization Techniques

1. **Input and Output Analysis**
   - **Input Layer:** The initial layer of the CNN where input data is fed.
   - **Output Layer:** The final layer where the network's predictions are made.
   - Intermediate layers are visualized to understand the transformation from input to output.

2. **Feature Maps**
   - Visualization of feature maps at various convolutional layers.
   - Helps in understanding the features learned by the network.

3. **Activation Maximization**
   - Techniques to visualize the most activating input patterns for specific neurons.
   - Useful for understanding what features the network is focusing on.

4. **Deconvolution**
   - Reversing the convolution process to generate input images from the activations.
   - This helps in visualizing which parts of the image are contributing to the activation of specific neurons.

### Diagram

A detailed diagram is shown, highlighting the different convolutional layers and the flow of data from input to output.
```

# DL4CV_Week06_Part01.pdf - Page 30

```markdown
# Summary: ‘Don’t-disturb-the-model’ methods

![Visualizing the filter/kernels (raw weights)](data:image/png;base64,...) 
- **Visualizing the filter/kernels (raw weights)**

![Convolution Process](data:image/png;base64,...) 
- **Conv**

*Vineeth N B (IIIT-H)*
*§6.1 Explaining CNNs: Visualization Methods*

---

This section discusses the visualization methods specifically designed to avoid disturbing the model. The methods aim to understand and illustrate the filter/kernels with their raw weights, providing insights into the model's decision-making process.

The visual representation of the convolutional layers (Conv) highlights the importance of visualizing the raw weights. The diagrams showcase the steps involved in the convolution process, which is critical for understanding the inner workings of the model.

---

*Page 13 / 15*
```

# DL4CV_Week06_Part01.pdf - Page 31

```markdown
# Summary: ‘Don’t-disturb-the-model’ methods

![Visualizing the filter/kernels (raw weights)](#)

- **Visualizing the filter/kernels (raw weights)**:
  - Only interpretable at the first layer!
  - Not interesting enough for higher layers!

![Conv diagram](#)

**Vineeth N B (IIT-H)**

## 6.1 Explaining CNNs: Visualization Methods

**13 / 15**
```

# DL4CV_Week06_Part01.pdf - Page 32

```markdown
# Summary: ‘Don’t-disturb-the-model’ methods

## Visualizing the filter/kernels (raw weights)

![Filter/Kernels Visualization](image-url)

- Only interpretable at the first layer!
- Not interesting enough for higher layers!

![Gabor-like filter fatigue](image-url)

## The Gabor-like filter fatigue

Vineeth N B (IIT-H)

---

Section 6.1 Explaining CNNs: Visualization Methods

13 / 15
```

# DL4CV_Week06_Part01.pdf - Page 33

```markdown
# Summary: ‘Don’t-disturb-the-model’ methods

![Visualizing the filter/kernels (raw weights)](../path/to/image.png)

- **Visualizing the filter/kernels (raw weights)**

    ![Diagram of convolution and pooling](../path/to/diagram.png)

    - **Conv:** Convolutional layer
    - **Pool:** Pooling layer

*Vineeth N B (IIT-H)*

*§6.1 Explaining CNNs: Visualization Methods*

---

### Convolutional Layer (Conv)
- The convolutional layer applies filters or kernels to the input data.
- It aims to extract features from the input by sliding the filter/kernel over the input data and performing element-wise multiplication followed by summation.

### Pooling Layer (Pool)
- The pooling layer reduces the spatial dimensions of the input.
- Common pooling operations include max pooling and average pooling, which downsample the feature maps by taking the maximum or average values over specified windows.

---

In the context of CNNs, these layers are fundamental for feature extraction and dimensionality reduction. By visualizing the raw weights of the filters/kernels, one can gain insights into the features learned by the model.
```

# DL4CV_Week06_Part01.pdf - Page 34

```markdown
# Summary: ‘Don’t-disturb-the-model’ methods

## Visualizing the filter/kernels (raw weights)

![Filter/Kernels Visualization](../path/to/image1.png)

## Visualize patches that maximally activate neuron

![Neuron Activation Visualization](../path/to/image2.png)

### Steps:
1. **Conv** (Convolution)
   - Highlighted in red.
   - Shows the process of visualizing the filter/kernels (raw weights).

2. **Pool** (Pooling)
   - Highlighted in blue.
   - Visualizes patches that maximally activate the neuron.

### Visualization Examples

![Activation Examples](../path/to/image3.png)

- The images depict different patches that maximally activate specific neurons in the neural network.

---

**Vineeth N B (IIT-H)**
**§6.1 Explaining CNNs: Visualization Methods**

---

**Slide Number:** 13 / 15
```

# DL4CV_Week06_Part01.pdf - Page 35

```markdown
# Summary: ‘Don’t-disturb-the-model’ methods

![Image of visualization methods](image_url)

## Visualizing the filter/kernels (raw weights)

- Visualizing the filter/kernels (raw weights)

## Visualize patches that maximally activate neuron

![Image of neuron activation patches](image_url)

## Conv

- The convolutional layer is represented here.
- Filter/kernels visualization is indicated with an arrow pointing to the left.
- Visualization of patches that maximally activate neurons in the convolutional layer.

## Pool

- The pooling layer is represented here.
- Filter/kernels visualization is indicated with an arrow pointing to the convolutional layer.
- Visualization of patches that maximally activate neurons in the pooling layer.

## FC

- Fully connected layer is represented here.
- Filter/kernels visualization is indicated with an arrow pointing to the pooling layer.
- Visualization of patches that maximally activate neurons in the fully connected layer.

---

**Vineeth N B (IIT-H)**

**§6.1 Explaining CNNs: Visualization Methods**

---

*Page 13 / 15*
```

# DL4CV_Week06_Part01.pdf - Page 36

```markdown
# Summary: ‘Don’t disturb the model’ methods

![Diagram](image-url)

## Visualizing the filter/kernels (raw weights)
- Visualizing the filter/kernels (raw weights)

## Visualizing the representation
- Visualizing the representation

![Diagram](image-url)

Visualize patches that maximally activate neuron

![Diagram](image-url)

### Steps:
1. **Conv**: Convolutional layer visualization
2. **Pool**: Pooling layer visualization
3. **FC**: Fully connected layer visualization

![Diagram](image-url)

Visualize patches that maximally activate neuron

### Examples:
1. **Image 1**: With activation score
   ![Example](example-image-url)
   - Score: 1.0

2. **Image 2**: With activation score
   ![Example](example-image-url)
   - Score: 0.9

3. **Image 3**: With activation score
   ![Example](example-image-url)
   - Score: 0.8

4. **Image 4**: With activation score
   ![Example](example-image-url)
   - Score: 0.7

### References:
- Vineeth N B. (IIT-H)
- §6.1 Explaining CNNs: Visualization Methods
- Slide 13 / 15
```

# DL4CV_Week06_Part01.pdf - Page 37

```markdown
# Summary: ‘Don’t-disturb-the-model’ methods

## Visualizing the filter/kernels (raw weights)

![Filter/Kernels Visualization](https://via.placeholder.com/150)

## Visualizing the representation

![t-SNE Visualization](https://via.placeholder.com/150)

![Representation Visualization](https://via.placeholder.com/150)

---

### Visualizing patches that maximally activate neuron

![Maximally Activated Neurons](https://via.placeholder.com/150)

## Visualization Methods

- **Visualizing the filter/kernels (raw weights)**: 
  - Example: ![Filter/Kernels](https://via.placeholder.com/150)

- **Visualizing the representation**: 
  - Example: ![Representation](https://via.placeholder.com/150) 

- **Visualizing patches that maximally activate neuron**:
  - Example: ![Maximally Activated Neurons](https://via.placeholder.com/150)

### Network Architecture

- **Conv (Convolutional Layer)**: 
  - Example: ![Conv Layer](https://via.placeholder.com/150)

- **Pool (Pooling Layer)**: 
  - Example: ![Pool Layer](https://via.placeholder.com/150)

- **FC (Fully Connected Layer)**: 
  - Example: ![FC Layer](https://via.placeholder.com/150)

### Techniques

- **t-SNE (t-Distributed Stochastic Neighbor Embedding)**: 
  - Example: ![t-SNE](https://via.placeholder.com/150)

---

### Author Information

- **Vineeth N B (IIIT-H)**

### Section

- **6.1 Explaining CNNs: Visualization Methods**

---

### Page Information

- **Page Number**: 13 / 15
```

This markdown format accurately captures the structure and content of the provided scientific slide, ensuring all important elements are represented correctly. The placeholders for images are included to indicate where visual content would be inserted.

# DL4CV_Week06_Part01.pdf - Page 38

```markdown
# Summary: ‘Don’t-disturb-the-model’ methods

![Visualizing the filter/kernels (raw weights)](image1.png)

- Visualizing the filter/kernels (raw weights)

![Visualizing the representation](image2.png)

- t-SNE (t-distributed Stochastic Neighbor Embedding)

![t-SNE visualization](image3.png)

- Visualizing the representation

---

**Vineeth N B (IIIT-H)**

**§6.1 Explaining CNNs: Visualization Methods**

---

## Visualizing the filter/kernels (raw weights)

- This method visualizes the raw weights of the filters/kernels in a convolutional neural network (CNN).
- The visualization helps in understanding the patterns and features learned by the convolutional layers.
- One can observe the different kernels and their contributions to the overall model performance.

## Visualizing the representation

- This method uses dimensionality reduction techniques such as t-SNE (t-distributed Stochastic Neighbor Embedding) to visualize the high-dimensional representations learned by the network.
- t-SNE is particularly useful for visualizing clusters and structure in the data.
- The visualization aids in interpreting which features or groups of features are significant in the decision-making process of the model.

## t-SNE Visualization

![t-SNE](image4.png)

- t-SNE embeds high-dimensional data into a lower-dimensional space, making it easier to visualize and interpret.
- This technique is commonly used in machine learning and data science to explore and understand the structure of data.
- Different clusters or patterns in the data can be identified, which helps in understanding the learned representations of the model.

---

Vineeth N B (IIIT-H)

**§6.1 Explaining CNNs: Visualization Methods**

---

```

# DL4CV_Week06_Part01.pdf - Page 39

```markdown
# Summary: ‘Don’t-disturb-the-model’ methods

## Visualizing filter/kernels (raw weights)

![Filter/Kernels](image-url)

## Visualizing the representation

![Representation](image-url)

## Visualizing patches that maximally activate neuron

![Patches](image-url)

## t-SNE

![t-SNE](image-url)

## Conv

![Conv](image-url)

## Pool

![Pool](image-url)

## Fully Connected Layer (FC)

![FC](image-url)

---

**Vineeth N B (IIIT-H) §6.1 Explaining CNNs: Visualization Methods**

13 / 15
```

# DL4CV_Week06_Part01.pdf - Page 40

```markdown
# Summary: ‘Don’t-disturb-the-model’ methods

## Visualizing the filter/kernels (raw weights)

![Filter/Kernels Visualization](image_url)

## Visualizing the representation

![Representation Visualization](image_url)

## t-SNE

![t-SNE Plot](image_url)

## Conv

![Convolutional Layer](image_url)

## Pool

![Pooling Layer](image_url)

## Visualize patches that maximally activate neuron

![Neuron Activation](image_url)

## FC

![Fully Connected Layer](image_url)

## Occlusion Experiment

![Occlusion Experiment](image_url)

## References

- Vineeth N B (IIIT-H)
- §6.1 Explaining CNNs: Visualization Methods

```

# DL4CV_Week06_Part01.pdf - Page 41

```markdown
# Summary: ‘Don’t-disturb-the-model’ methods

## Visualizing the filter/kernels (raw weights)

![Filter/Kernels](image_url_for_filter_kernels)

## Visualizing the representation

![Representation](image_url_for_representation)

## Visualizing patches that maximally activate neuron

### Input Conv

![Input Conv](image_url_for_input_conv)

### Pool

![Pool](image_url_for_pool)

### FC

![FC](image_url_for_fc)

### Occlusion Experiment

![Occlusion Experiment](image_url_for_occlusion_experiment)

---

Vineeth N B (IIT-H)

§6.1 Explaining CNNs: Visualization Methods

---

## Key Techniques

- **Visualizing the filter/kernels (raw weights)**: This involves analyzing the initial weights of the convolutional layers.

- **Visualizing the representation**: This technique focuses on understanding the representation learned by the network.

- **Visualizing patches that maximally activate neurons**: This method highlights the input patches that lead to the maximum activation of specific neurons within the network.

- **Occlusion Experiment**: This method involves masking parts of the input to observe how it affects the network’s predictions and understand which parts of the input are crucial for the model's decision-making process.

## Visualization Patches

### Image Examples

![Image Examples](image_url_for_image_examples)

```markdown
# Example Images and Activations

1. **Children**: 
   - ![Child 1](image_url_for_child_1) 
   - ![Child 2](image_url_for_child_2) 
   - ![Child 3](image_url_for_child_3) 
   - ![Child 4](image_url_for_child_4)

2. **Dogs**:
   - ![Dog 1](image_url_for_dog_1) 
   - ![Dog 2](image_url_for_dog_2) 
   - ![Dog 3](image_url_for_dog_3) 
   - ![Dog 4](image_url_for_dog_4)

3. **Nature**:
   - ![Nature 1](image_url_for_nature_1) 
   - ![Nature 2](image_url_for_nature_2) 
   - ![Nature 3](image_url_for_nature_3) 
   - ![Nature 4](image_url_for_nature_4)

4. **Occlusion Examples**:
   - ![Occlusion 1](image_url_for_occlusion_1) 
   - ![Occlusion 2](image_url_for_occlusion_2) 
   - ![Occlusion 3](image_url_for_occlusion_3) 
   - ![Occlusion 4](image_url_for_occlusion_4)
```

---

This markdown document provides an organized summary of the methods used to visualize and understand the internal workings of convolutional neural networks (CNNs). It includes explanations, image examples, and detailed visual representations to illustrate the techniques of visualizing raw weights, learned representations, neuron activations, and occlusion experiments.
```

# DL4CV_Week06_Part01.pdf - Page 42

```markdown
# Summary: ‘Don’t-disturb-the-model’ methods

![Image](https://via.placeholder.com/150)

Visualizing the filter/kernels (raw weights)

![Image](https://via.placeholder.com/150)

Visualizing the representation

![Diagram](https://via.placeholder.com/150)

- Visualize patches that maximally activate neuron

## Visualizing the filter/kernels (raw weights)

Visualizing the raw weights of the filters/kernels is essential to understand the initial stages of the convolutional neural network (CNN). This helps in interpreting what the network is learning at the basic level.

## Visualizing the representation

Visualizing the representation involves using techniques such as t-SNE (t-distributed Stochastic Neighbor Embedding) to reduce the dimensionality of the data and visualize it in a two-dimensional space. This helps in understanding the higher-level features learned by the network.

## t-SNE

t-SNE is a technique used for dimensionality reduction which is particularly well-suited for the visualization of high-dimensional data. It helps to visualize the representation learned by the CNN.

### Input Conv

![Diagram](https://via.placeholder.com/150)

### Pool

![Diagram](https://via.placeholder.com/150)

### Fully Connected (FC)

![Diagram](https://via.placeholder.com/150)

### Occlusion Experiment

![Experiment](https://via.placeholder.com/150)

## Visualization Methods

### Visualize patches that maximally activate neuron

This method involves identifying and visualizing the image patches that cause the neurons in the network to activate maximally. This helps in understanding what specific features or patterns the neurons are focusing on.

### Occlusion Experiment

The occlusion experiment involves masking parts of the image to observe how the network's predictions change. This helps in identifying which parts of the image are most important for the network's decision-making process.

![Experiment](https://via.placeholder.com/150)

### Examples

- **Children:**
  - ![Image](https://via.placeholder.com/150) 1.0
  - ![Image](https://via.placeholder.com/150) 0.9
  - ![Image](https://via.placeholder.com/150) 0.7
  - ![Image](https://via.placeholder.com/150) 0.6

- **Dogs:**
  - ![Image](https://via.placeholder.com/150) 1.0
  - ![Image](https://via.placeholder.com/150) 0.8
  - ![Image](https://via.placeholder.com/150) 0.7
  - ![Image](https://via.placeholder.com/150) 0.5

- **Scenery:**
  - ![Image](https://via.placeholder.com/150) 1.0
  - ![Image](https://via.placeholder.com/150) 0.9
  - ![Image](https://via.placeholder.com/150) 0.8
  - ![Image](https://via.placeholder.com/150) 0.7

- **Heatmaps:**
  - ![Image](https://via.placeholder.com/150) Original
  - ![Image](https://via.placeholder.com/150) Heatmap 1
  - ![Image](https://via.placeholder.com/150) Heatmap 2
  - ![Image](https://via.placeholder.com/150) Heatmap 3

### Reference

Vineeth N B (IIIT-H)

### Section

§6.1 Explaining CNNs: Visualization Methods

### Slide Number

13 / 15
```

# DL4CV_Week06_Part01.pdf - Page 43

```markdown
# Summary: 'Don't-disturb-the-model' methods

## Visualizing the filter/kernels (raw weights)

![Filter/Kernels Visualization](image_url)

## Visualizing the representation

![Representation Visualization](image_url)

## t-SNE

![t-SNE](image_url)

## Input Conv

![Input Conv](image_url)

## Pool

![Pool](image_url)

## Visualize patches that maximally activate neuron

![Maximally Activate Neuron](image_url)

## Fully Connected Layer (FC)

![Fully Connected Layer](image_url)

## Occlusion Experiment

![Occlusion Experiment](image_url)

_Visualizing the filter/kernels (raw weights):_

- Visual representation of filter/kernels

_Visualizing the representation:_

- Visual representation of the model's internal states

_t-SNE:_

- t-SNE method for dimensionality reduction and visualization

_Input Conv:_

- Input convolutional layer visualization

_Pool:_

- Pooling layer visualization

_Visualize patches that maximally activate neuron:_

- Patch visualization that maximally activates specific neurons

_Fully Connected Layer (FC):_

- Fully connected layer visualization

_Occlusion Experiment:_

- Experiment to test the importance of different regions in images

*Vineeth N B (IIIT-H) §6.1 Explaining CNNs: Visualization Methods*

---

**Note:** Replace `image_url` placeholders with actual URLs or paths to the images if available.
```

# DL4CV_Week06_Part01.pdf - Page 44

```markdown
# Homework Readings

## Readings

### Summary of Visualizing CNNs

- **Lecture Notes of CS231n, Stanford**

### Miscellaneous

- Deep Visualization Toolkit demo video and webpage by J. Yosinski et al.
- To see high-resolution t-SNE visualizations, visit [here](#).
- To know more about t-SNE, visit [here](#).

_Vineeth N B (IIT-H)_

_Section 6.1 Explaining CNNs: Visualization Methods_

_Page 14 of 15_
```

# DL4CV_Week06_Part01.pdf - Page 45

# References

- Laurens van der Maaten and Geoffrey E. Hinton. **"Visualizing Data using t-SNE".** In: 2008.
- Ross Girshick et al. **"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation".** In: *Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition* (Nov. 2013).
- Matthew D. Zeiler and Rob Fergus. **"Visualizing and Understanding Convolutional Networks".** In: *ECCV*. 2014.
- Jost Tobias Springenberg et al. **"Striving for Simplicity: The All Convolutional Net".** In: *CoRR* abs/1412.6806 (2015).

---

Vineeth N B (IIT-H) §6.1 Explaining CNNs: Visualization Methods 15 / 15

