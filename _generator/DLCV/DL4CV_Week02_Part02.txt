# DL4CV_Week02_Part02.pdf - Page 1

```markdown
# Deep Learning for Computer Vision

# From Edges to Blobs and Corners

**Vineeth N Balasubramanian**

Department of Computer Science and Engineering
Indian Institute of Technology, Hyderabad

![IIT Hyderabad Logo](https://example.com/logo)

*Vineeth N B (IIT-H) §2.2 Blob and Corner Detection*

---

### Deep Learning for Computer Vision

**Vineeth N Balasubramanian**

Department of Computer Science and Engineering
Indian Institute of Technology, Hyderabad

---

#### §2.2 Blob and Corner Detection

- **Introduction**
  - Discuss the importance of blob and corner detection in computer vision.
  - Explain the basic concepts and definitions.

- **Methods for Blob Detection**
  - **Mean Shift Algorithm**
    - Describes how the mean shift algorithm works.
    - Example code snippet:
      ```python
      def mean_shift(image):
          # Mean Shift algorithm implementation
          pass
      ```
  - **Blob Detection using Deep Learning**
    - Explain how deep learning models can be used for blob detection.
    - Example architecture:
      ```markdown
      Convolutional Layer -> Pooling Layer -> Fully Connected Layer
      ```
    - Mathematical representation of blob detection formula:
      $$ \text{Blob} = \sum_{i=1}^{n} f(i) $$

- **Methods for Corner Detection**
  - **Harris Corner Detector**
    - Describes the Harris corner detector method.
    - Example computation:
      ```math
      \text{det}(M) - k \cdot \text{trace}(M)^2
      ```
  - **SUSAN Corner Detection**
    - Explain the SUSAN (Smallest Unvalidated Area) corner detection method.
    - Example pseudocode:
      ```python
      function susan(image):
          # SUSAN algorithm implementation
          pass
      ```

- **Applications**
  - Discuss real-world applications of blob and corner detection.
  - Examples in image processing and computer vision tasks.

- **Conclusion**
  - Summarize the key points discussed in the section.
  - Future directions and potential improvements.

---

**References**
- List relevant references and literature used for blob and corner detection.
  - Example:
    - Reference 1: "Title of the Paper", Author, Journal, Year.
    - Reference 2: "Another Paper", Author, Conference Proceedings, Year.

---

### Additional Notes

- **Figure 1: Example Image with Detected Blobs**
  ![Example Blob Detection](https://example.com/blob_example.png)

- **Figure 2: Example Image with Detected Corners**
  ![Example Corner Detection](https://example.com/corner_example.png)

---

**Contact Information**

- **Vineeth N Balasubramanian**
- **Email**: vineeth@iit.ac.in
- **Phone**: +91 1234 567890
```

# DL4CV_Week02_Part02.pdf - Page 2

```markdown
# Review: Using Canny Edges to get Straight Lines

- **Compute Canny edges**
  - Compute \(\nabla_x f, \nabla_y f\) (gradients in \(x, y\) directions)
  - Compute \(\theta = \tan^{-1} \frac{\nabla_y f}{\nabla_x f}\)
- **Assign each edge to one of 8 directions.** For each direction \(d\), obtain **"edgelets"**:
  - Find connected components for edge pixels with directions in \(\{d-1, d, d+1\}\)
 
![NPTEL](image.png)

*Vineeth N B (IIT-H) §2.2 Blob and Corner Detection 2 / 27*
```

# DL4CV_Week02_Part02.pdf - Page 3

```markdown
# Review: Using Canny Edges to get Straight Lines

- **Compute Canny edges**
  - Compute \(\nabla_x f, \nabla_y f\) (gradients in \(x, y\) directions)
  - Compute \(\theta = \tan^{-1} \frac{\nabla_y f}{\nabla_x f}\)

- **Assign each edge to one of 8 directions.** For each direction \(d\), obtain “edgelets”:
  - Find connected components for edge pixels with directions in \(\{d-1, d, d+1\}\)

- **Compute straightness and orientation, \(\theta\) of edgelets using eigenvectors and eigenvalues of second moment matrix, \(M\), of edge pixels**

  \[
  M = \begin{bmatrix}
  \sum (x - \mu_x)^2 & \sum (x - \mu_x)(y - \mu_y) \\
  \sum (y - \mu_y)(x - \mu_x) & \sum (y - \mu_y)^2
  \end{bmatrix}
  \quad
  [v, \lambda] = \text{eig}(M)
  \]

  \[
  \theta = \tan^{-1} \frac{v_1}{v_0} \quad \text{where} \, v_1 \, \text{is the `larger' eigenvector;} \quad \text{straightness} = \lambda_2 / \lambda_1
  \]

- **Threshold straightness appropriately and store line segments**

*Credit: Derek Hoiem*

*Vineeth N B (IIT-H)*

*§2.2 Blob and Corner Detection*

*2 / 27*
```

# DL4CV_Week02_Part02.pdf - Page 4

```markdown
# Review: Using Canny Edges to get Straight Lines

![Canny Edges to get Straight Lines](https://via.placeholder.com/150)

**Credit**: Derek Hoiem

Vineeth N B (IIT-H)

## §2.2 Blob and Corner Detection

3 / 27
```

# DL4CV_Week02_Part02.pdf - Page 5

```markdown
# Going Further to a Second Derivative

- **What if we took the Laplacian of Gaussian?**

![Gaussian](image_url)

```math
h_\sigma(u, v) = \frac{1}{2\pi\sigma^2} e^{-\frac{u^2 + v^2}{2\sigma^2}}
```

![Derivative of Gaussian](image_url)

```math
\frac{\partial}{\partial x} h_\sigma(u, v)
```

![Laplacian of Gaussian](image_url)

```math
\nabla^2 h_\sigma(u, v)
```

```math
\text{Laplacian} \quad \nabla^2 f = \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2}
```

**Credit:** S Seitz, K Grauman

*Vineeth N B (IIT-H)*

§2.2 Blob and Corner Detection

4 / 27
```

# DL4CV_Week02_Part02.pdf - Page 6

```markdown
# Laplacian of Gaussian

![Laplacian of Gaussian](image_url) 

## Example of a 3 x 3 Laplacian of Gaussian filter:

```markdown
\[
\begin{bmatrix}
0 & 1 & 0 \\
1 & -4 & 1 \\
0 & 1 & 0 \\
\end{bmatrix}
\]
```

**How did we obtain this filter?**
  
Vineeth N B (IIIT-H) §2.2 Blob and Corner Detection NPTEL 5 / 27
```

# DL4CV_Week02_Part02.pdf - Page 7

```markdown
# Laplacian of Gaussian

- **Discrete approximation of the second derivative:**

## Example of a 3 x 3 Laplacian of Gaussian filter:

\[
\begin{bmatrix}
0 & 1 & 0 \\
1 & -4 & 1 \\
0 & 1 & 0 \\
\end{bmatrix}
\]

### How did we obtain this filter?

\[
\frac{\partial^2 f}{\partial x^2} = f(x+1, y) + f(x-1, y) - 2f(x, y)
\]

\[
\frac{\partial^2 f}{\partial y^2} = f(x, y+1) + f(x, y-1) - 2f(x, y)
\]

Substituting in the LoG equation:

\[
\nabla^2 f = \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2}
\]

\[
\nabla^2 f = f(x+1, y) + f(x-1, y) + f(x, y+1) + f(x, y-1) - 4f(x, y)
\]

- **Converting this equation to a filter results in the given LoG matrix.**

_Vineeth N B (IIIT-H)_

§2.2 Blob and Corner Detection

5 / 27
```

# DL4CV_Week02_Part02.pdf - Page 8

```markdown
# Laplacian of Gaussian

## Original Image

![Original Image](image_url)

## Laplacian

![Laplacian](image_url)

## Laplacian of Gaussian

![Laplacian of Gaussian](image_url)

*Vineeth N B (IIIT-H)*

*Section 2.2 Blob and Corner Detection*

*NPTEL*

*6 / 27*
```

# DL4CV_Week02_Part02.pdf - Page 9

```markdown
# Laplacian of Gaussian

## Original Image

![Original Image](original_image.png)

## Laplacian

![Laplacian](laplacian_image.png)

## Laplacian of Gaussian

![Laplacian of Gaussian](log_image.png)

**What else can LoG do?**

*Credit: K Grauman*
*Vineeth N B (IIT-H)*
*§2.2 Blob and Corner Detection*

---

6 / 27
```

# DL4CV_Week02_Part02.pdf - Page 10

```markdown
# LoG as a Blob Detector

- Recall that convolution with a filter can be viewed as comparing a little "picture" of what you want to find against all local regions in the image.

![LoG Filter Visualization](image_url_placeholder)
![LoG Filter Matrix](image_url_placeholder)
![Blob Detection Result](image_url_placeholder)

- Observing the LoG filter matrix reveals that it is circularly symmetric. Thus it can be used for blob detection!

**Credit:** S Lazebnik

_Vineeth N B (IIIT-H)_

## §2.2 Blob and Corner Detection

Page 7 / 27
```

# DL4CV_Week02_Part02.pdf - Page 11

```markdown
# From Blobs to Corners

- In the following image, what are some interesting features to choose?

![Image](image_url)

*Credit: K Grauman, R Urtasun*

*Vineeth N B (IIT-H)*

## §2.2 Blob and Corner Detection

8 / 27
```

# DL4CV_Week02_Part02.pdf - Page 12

```markdown
# From Blobs to Corners

- Look for image regions that are unusual. How to define "unusual"?
- Textureless patches are nearly impossible to localize.
- Patches with large contrast changes (gradients) are easier to localize.
- But straight line segments at a single orientation suffer from the **aperture problem** (we'll see next slide), i.e., it is only possible to align the patches along the direction normal to the edge direction.
- Gradients in at least two (significantly) different orientations are the easiest, e.g., corners.

*Credit: R Urtasun*

_Vineeth N B (IIIT-H)_

## §2.2 Blob and Corner Detection

9 / 27
```

# DL4CV_Week02_Part02.pdf - Page 13

```markdown
# From Blobs to Corners

- Consider a small window of pixels. How does the window change when you shift it?

![Image with three different pixel window shifts](image-url)

## Description

### "flat" region:
- **No change in all directions**

### "edge":
- **No change along the edge direction**

### "corner":
- **Significant change in all directions**

**Credit:** S. Seitz, D. Frolova, D. Simakova, R. Urtasun

*Vineeth N B (IIT-H)*

*§2.2 Blob and Corner Detection*

Page: 10 / 27
```

# DL4CV_Week02_Part02.pdf - Page 14

```markdown
# Autocorrelation

- In the previous slide, how to quantify the "significant" change of the window?

![NPTEL Logo](https://via.placeholder.com/150)

**Vineeth N B (IIT-H)**

## §2.2 Blob and Corner Detection

---

_Note: This content is part of a presentation from NPTEL, specifically covering topics related to autocorrelation, blob detection, and corner detection in computer vision._

```

# DL4CV_Week02_Part02.pdf - Page 15

```markdown
# Autocorrelation

- **In the previous slide, how to quantify the "significant" change of the window?**

- **Answer: Autocorrelation function.** Compute the sum of squared differences between pixel intensities with respect to small variations in the image patch position.

    \[
    E_{AC}(\Delta u) = \sum_{x, y} w(p_i) [l(p_i + \delta u) - l(p_i)]^2
    \]

    where \( p_i = (x, y) \), a particular position on the image.

    ![Window Function](https://example.com/window_function.png)

    **Window function \( W(x, y) \)**:

    * 1 in window, 0 outside
    * Gaussian

**Credit:** R Urtasun
Vineeth N B (IIT-H)
s2.2 Blob and Corner Detection
11 / 27
```

# DL4CV_Week02_Part02.pdf - Page 16

```markdown
# Computing Autocorrelation

- **Using a Taylor Series expansion** \( I(\mathbf{p}_i + \Delta \mathbf{u}) = I(\mathbf{p}_i) + \nabla I(\mathbf{p}_i) \Delta \mathbf{u} \) with the image gradient

  \[
  \nabla I(\mathbf{p}_i) = \left( \frac{\delta I(\mathbf{p}_i)}{\delta x}, \frac{\delta I(\mathbf{p}_i)}{\delta y} \right)
  \]

---

**Vineeth N B (IIT-H)**

**§2.2 Blob and Corner Detection**

_NPTel_

![NPTel Logo](#) 

12 / 27
```

# DL4CV_Week02_Part02.pdf - Page 17

```markdown
# Computing Autocorrelation

- Using a Taylor Series expansion \( I(\mathbf{p}_i + \Delta \mathbf{u}) = I(\mathbf{p}_i) + \nabla I(\mathbf{p}_i) \Delta \mathbf{u} \) with the image gradient
  \[
  \nabla I(\mathbf{p}_i) = \left( \frac{\delta I(\mathbf{p}_i)}{\delta x}, \frac{\delta I(\mathbf{p}_i)}{\delta y} \right)
  \]

- Autocorrelation can be approximated as:
  \[
  E_{AC}(\Delta \mathbf{u}) = \sum_{x, y} w(\mathbf{p}_i) [I(\mathbf{p}_i + \delta \mathbf{u}) - I(\mathbf{p}_i)]^2
  \]
  \[
  \approx \sum_{x, y} w(\mathbf{p}_i) [I(\mathbf{p}_i) + \delta I(\mathbf{p}_i) \delta \mathbf{u} - I(\mathbf{p}_i)]^2
  \]
  \[
  = \sum_{x, y} w(\mathbf{p}_i) [\delta I(\mathbf{p}_i) \delta \mathbf{u}]^2
  \]
  \[
  = \Delta \mathbf{u}^T A \Delta \mathbf{u}
  \]

*Credit: R Urtasun*

*Vineeth N B (IIT-H)*

*§2.2 Blob and Corner Detection*

*12 / 27*
```

# DL4CV_Week02_Part02.pdf - Page 18

```markdown
# Computing Autocorrelation

- The autocorrelation is \( E_{AC}(\Delta \mathbf{u}) = \Delta \mathbf{u}^T A \Delta \mathbf{u} \), with

\[
\mathbf{A} = \sum_{u} \sum_{v} w(u, v) \begin{bmatrix} I_x^2 & I_x I_y \\ I_x I_y & I_y^2 \end{bmatrix} = w^* \begin{bmatrix} I_x^2 & I_x I_y \\ I_x I_y & I_y^2 \end{bmatrix}
\]

- The weighted summations have been replaced with discrete convolutions with the weighting kernel \( w \).

- The eigenvalues of \( \mathbf{A} \) reveal the amount of intensity change in the two principal orthogonal gradient directions in the window.

\[
\mathbf{A} = \mathbf{U} \begin{bmatrix} \lambda_1 & 0 \\ 0 & \lambda_2 \end{bmatrix} \mathbf{U}^T \quad \text{with} \quad \mathbf{A} \mathbf{u}_i = \lambda_i \mathbf{u}_i
\]

*Credit: R Urtasun*

_Vineeth N B (IIIT-H) §2.2 Blob and Corner Detection 13 / 27_
```

# DL4CV_Week02_Part02.pdf - Page 19

```markdown
# Computing Autocorrelation

- How do the eigenvalues determine if an image point is a corner?

![NPTEL Logo](image_url)

**Vineeth N B (IIT-H)**  
**§2.2 Blob and Corner Detection**

Page 14 / 27
```

# DL4CV_Week02_Part02.pdf - Page 20

```markdown
# Computing Autocorrelation

- **How do the eigenvalues determine if an image point is a corner?**

![Eigenvalues and Image Point Classification](image_url)

- **Edge**
  - $\lambda_2 \gg \lambda_1$
  - $\lambda_1$ and $\lambda_2$ are large
  - $E$ increases in all directions

- **Corner**
  - $\lambda_1$ and $\lambda_2$ are large
  - $\lambda_1 \sim \lambda_2$
  - $E$ increases in all directions

- **Flat region**
  - $\lambda_1$ and $\lambda_2$ are small
  - $E$ is almost constant in all directions

- **Edge**
  - $\lambda_1 \gg \lambda_2$

**Credit:** N Snavely, R Urtasun

Vineeth N B (IIT-H)

§2.2 Blob and Corner Detection

Page 14 / 27
```

# DL4CV_Week02_Part02.pdf - Page 21

```markdown
# Computing Autocorrelation

![Autocorrelation Diagram](image_url)

## Credit: K Grauman, R Urtasun

### Vineeth N B (IIIT-H) §2.2 Blob and Corner Detection

The process of computing autocorrelation is depicted through three main scenarios:

1. **"edge"**:
   - Characteristics: 
     - λ₁ >> λ₂
     - λ₂ >> λ₁

   ![Edge Diagram](image_url)

2. **"corner"**:
   - Characteristics:
     - λ₁ and λ₂ are large
     - λ₁ ~ λ₂

   ![Corner Diagram](image_url)

3. **"flat" region**:
   - Characteristics:
     - λ₁ and λ₂ are small

   ![Flat Region Diagram](image_url)
```

# DL4CV_Week02_Part02.pdf - Page 22

```markdown
# Harris Corner Detector

- **Compute gradients** at each point in the image.

- **Compute A** for each image window to get its cornerness scores.

- **Compute the eigenvalues**/**compute the following function** \(M_c\)

  \[
  M_c = \lambda_1 \lambda_2 - \kappa (\lambda_1 + \lambda_2)^2 = \det(A) - \kappa \operatorname{trace}^2(A)
  \]

- **Find points** whose surrounding window gave larger cornerness response (\(M_c > \text{threshold}\))

- **Take points of local maxima**, perform non-maximum suppression.

*Credit: R Urtasun*

_Vineeth N B (IIIT-H) §2.2 Blob and Corner Detection 16 / 27_
```

# DL4CV_Week02_Part02.pdf - Page 23

```markdown
# Harris Corner Detector: Example

![Harris Corner Detector Example](image_url)

**Credit:** K Grauman, R Urtasun

Vineeth N B (IIT-H)

## §2.2 Blob and Corner Detection

The image depicts an example of the Harris Corner Detector applied to a structure. The corner detection helps in identifying significant features within the image, which is crucial for tasks such as image matching, object recognition, and image segmentation.

### Harris Corner Detection Process

1. **Image Preprocessing**: The input image is preprocessed to enhance the features and reduce noise. This may involve techniques like smoothing or edge detection.

2. **Gradient Calculation**: The image gradients are computed using derivatives. Typically, the image is convolved with Sobel operators to calculate the gradients in the x and y directions.

3. **Structure Tensor Calculation**: The structure tensor is computed using the gradient information. The tensor provides insight into the local intensity patterns around each pixel.

   The structure tensor \( M \) is given by:
   \[
   M = \begin{bmatrix}
   I_x^2 & I_x I_y \\
   I_x I_y & I_y^2
   \end{bmatrix}
   \]

4. **Eigenvalue Decomposition**: The eigenvalues of the structure tensor are computed. These eigenvalues help in determining the corner strength.

5. **Corner Response Function**: The corner response function, often the determinant or trace of the structure tensor, is used to identify potential corners.

The corner detection is illustrated here with a toy figure where significant features are highlighted. This demonstrates how the Harris Corner Detector can be applied to real-world images to detect and analyze corners effectively.

```

# DL4CV_Week02_Part02.pdf - Page 24

```markdown
# Computing Cornerness

![Heatmap](image_url_here)

**Credit**: *K Grauman, R Urtasun*

*Vineeth N B (IIT-H)*

### §2.2 Blob and Corner Detection

- OCR might not capture images directly, use placeholders like `image_url_here`.

- Ensure all **bold** and *italicized* text is correctly formatted.

- Maintain paragraph and list structure clearly.

- Use proper markdown syntax for headings and subheadings.

- Ensure all scientific terms, symbols, and formulas are accurately captured.

Example:

```markdown
## Example Heading

This is an example paragraph with **bold** and *italic* text.

### Subheading

- Bullet point 1
- Bullet point 2

### Numbered List

1. First item
2. Second item
3. Third item

### Code Block

```python
# This is a code block
print("Hello, World!")
```

### Math Equation

Inline math: \( E = mc^2 \)

Block math:

$$
\int_{a}^{b} f(x) \, dx
$$

### Diagrams and Images

```markdown
![Diagram Title](image_url_here)
```

### Tables

```markdown
| Header 1 | Header 2 |
|----------|----------|
| Cell 1   | Cell 2   |
| Cell 3   | Cell 4   |
```

```

# DL4CV_Week02_Part02.pdf - Page 25

```markdown
# Finding High Response

![Finding High Response Image](image-url)

Credit: K Grauman, R Urtasun

Vineeth N B (IIT-H)

## §2.2 Blob and Corner Detection

19 / 27
```

# DL4CV_Week02_Part02.pdf - Page 26

```markdown
# Non-max Suppression

![Non-max Suppression Image](image_url)

**Credit:** K Grauman, R Urtasun

**Vineeth N B (IIT-H)**

## §2.2 Blob and Corner Detection

Page: 20 / 27
```

The above markdown format ensures the content is organized, formatted, and presented accurately. If you have additional requirements or further sections from the scientific text or slides, feel free to provide them, and I'll continue the conversion process.

# DL4CV_Week02_Part02.pdf - Page 27

```markdown
# Results

![Image](image-url)

Credit: **K Grauman, R Urtasun**

Vineeth N B (IIT-H)

§2.2 Blob and Corner Detection

![Diagram](diagram-url)

## Diagram Description

The image shows a comparison of detection results on a target object. The object appears to be a toy giraffe. The yellow circles highlight the regions where blobs and corners are detected. 

- **Left Image**: Shows the initial detection results.
- **Right Image**: Shows refined detection results with emphasized regions.

## Key Points

- **Blob Detection**: Identified using circles that highlight the significant regions of interest on the object.
- **Corner Detection**: Highlighted regions focus on the key structural points of the object.

Page Number: 21 / 27
```

# DL4CV_Week02_Part02.pdf - Page 28

```markdown
# Harris Corner Detector: Variants

- Harris and Stephens '88 is rotationally invariant and downweights edge-like features where \(\lambda_1 >> \lambda_0\).

  \[
  \text{det}(\mathbf{A}) - \alpha \text{trace}(\mathbf{A})^2 = \lambda_0 \lambda_1 - \alpha (\lambda_0 + \lambda_1)^2
  \]

- Triggs '04 suggested \(\lambda_0 - \alpha \lambda_1\).

  ![Image placeholder](image_url)

- Brown et al., '05 use harmonic mean:

  \[
  \frac{\text{det}(\mathbf{A})}{\text{trace}(\mathbf{A})} = \frac{\lambda_0 \lambda_1}{\lambda_0 + \lambda_1}
  \]

  which is smoother when \(\lambda_0 \approx \lambda_1\).

*Credit: R Urtasun*

_Vineeth N B (IIT-H) §2.2 Blob and Corner Detection_

22 / 27
```

# DL4CV_Week02_Part02.pdf - Page 29

```markdown
# Harris Corner Detector: Properties

- **Scale-invariant?**
  ![Harris Corner Detector Visual](image_url)

  All points will be classified as edges.

  *Credit: R Urtasun*

## Slide Information
- **Presenter**: Vineeth N B (IIT-H)
- **Section**: §2.2 Blob and Corner Detection
- **Slide Number**: 23 / 27

![NPTEL Logo](image_url)
```

# DL4CV_Week02_Part02.pdf - Page 30

```markdown
# Harris Corner Detector: Properties

- **Rotation-invariant?**

  \[
  A = w \times \left[\begin{array}{cc}
  l_x^2 & l_x l_y \\
  l_y l_x & l_y^2
  \end{array}\right] = U \left[\begin{array}{cc}
  \lambda_0 & 0 \\
  0 & \lambda_1
  \end{array}\right] U^T \quad \text{with} \quad A u_i = \lambda_i u_i
  \]

- Relative coreness remains the same!

![Relative Coreness Image](image_placeholder.png)

*Credit: N Snavely, R Urtasun*

*Vineeth N B (IIT-H) §2.2 Blob and Corner Detection*

*Date: 24 / 27*
```

# DL4CV_Week02_Part02.pdf - Page 31

```markdown
# Harris Corner Detector: Properties

- **Photometric change**: Affine intensity change \( I = aI + b \)
- Only derivatives are used, so it's invariant to shift \( I = I + b \).
- What about intensity scale?

![Graph depicting the Harris Corner Detector properties](image_url)

**Partially invariant to affine intensity change**

*Credit: K Grauman, R Urtasun*

*Vineeth N B (IIT-H)*

*§2.2 Blob and Corner Detection*

*25 / 27*
```

# DL4CV_Week02_Part02.pdf - Page 32

```markdown
# Homework

## Homework Readings

### Homework

#### Reaadings

- Chapter 2, Szeliski, *Computer Vision: Algorithms and Applications*

### Questions: Linear Algebra review

- Show that the trace of a matrix is the sum of its eigenvalues.

- Show that the determinant of a matrix is the product of its eigenvalues.
```

# DL4CV_Week02_Part02.pdf - Page 33

```markdown
# References

- C. Harris and M. Stephens. "A Combined Corner and Edge Detector". In: *Proceedings of the 4th Alvey Vision Conference*. 1988, pp. 147–151.

- Bill Triggs. "Detecting Keypoints with Stable Position, Orientation, and Scale under Illumination Changes". In: *Computer Vision - ECCV 2004*. Ed. by Tomás Pajdla and Jiri Matas. Berlin, Heidelberg: Springer Berlin Heidelberg, 2004, pp. 100–113.

- M. Brown, R. Szeliski, and S. Winder. "Multi-image matching using multi-scale oriented patches". In: *2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)*. Vol. 1. 2005, 510–517 vol. 1.

- Richard Szeliski. *Computer Vision: Algorithms and Applications*. Texts in Computer Science. London: Springer-Verlag, 2011.

- David Forsyth and Jean Ponce. *Computer Vision: A Modern Approach*. 2 edition. Boston: Pearson Education India, 2015.
```

