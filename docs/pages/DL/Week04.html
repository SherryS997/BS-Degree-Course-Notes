<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.550">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>BS Degree Notes - Variations in Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="https://lalten.github.io/lmweb/style/latinmodern-roman.css">
<link rel="stylesheet" href="https://lalten.github.io/lmweb/style/latinmodern-sans.css">
<link rel="stylesheet" href="https://lalten.github.io/lmweb/style/latinmodern-mono.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../pages/DL/Week01_1.html">Deep Learning</a></li><li class="breadcrumb-item"><a href="../../pages/DL/Week04.html">Week 4</a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">BS Degree Notes</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/DL/Week01_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 1.1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/DL/Week01_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 1.2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/DL/Week02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/DL/Week03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 3</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/DL/Week04.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Week 4</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/DL/Week05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 5</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/DL/Week06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 6</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
 <span class="menu-text">AI: Search Methods</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/AI/Week01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/AI/Week02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/AI/Week03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 3</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/AI/Week04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 4</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/AI/Week05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 5</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/AI/Week06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 6</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">
 <span class="menu-text">Software Testing</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/ST/Week01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/ST/Week02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/ST/Week03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 3</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/ST/Week04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 4</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false">
 <span class="menu-text">Software Engineering</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/SE/Week01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/SE/Week02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/SE/Week03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 3</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/SE/Week04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 4</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false">
 <span class="menu-text">Reinforcement Learning</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/RL/Week01_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 1.1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/RL/Week01_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 1.2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/RL/Week02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 2</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#understanding-contour-maps" id="toc-understanding-contour-maps" class="nav-link active" data-scroll-target="#understanding-contour-maps">Understanding Contour Maps</a>
  <ul class="collapse">
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#construction-of-contour-maps" id="toc-construction-of-contour-maps" class="nav-link" data-scroll-target="#construction-of-contour-maps">Construction of Contour Maps</a>
  <ul class="collapse">
  <li><a href="#slicing-the-surface" id="toc-slicing-the-surface" class="nav-link" data-scroll-target="#slicing-the-surface">Slicing the Surface</a></li>
  <li><a href="#labeling-the-slices" id="toc-labeling-the-slices" class="nav-link" data-scroll-target="#labeling-the-slices">Labeling the Slices</a></li>
  <li><a href="#viewing-from-the-top" id="toc-viewing-from-the-top" class="nav-link" data-scroll-target="#viewing-from-the-top">Viewing from the Top</a></li>
  </ul></li>
  <li><a href="#interpreting-contour-maps" id="toc-interpreting-contour-maps" class="nav-link" data-scroll-target="#interpreting-contour-maps">Interpreting Contour Maps</a>
  <ul class="collapse">
  <li><a href="#slope-analysis" id="toc-slope-analysis" class="nav-link" data-scroll-target="#slope-analysis">Slope Analysis</a></li>
  <li><a href="#level-values" id="toc-level-values" class="nav-link" data-scroll-target="#level-values">Level Values</a></li>
  </ul></li>
  <li><a href="#application-to-gradient-descent" id="toc-application-to-gradient-descent" class="nav-link" data-scroll-target="#application-to-gradient-descent">Application to Gradient Descent</a>
  <ul class="collapse">
  <li><a href="#movement-on-contour-maps" id="toc-movement-on-contour-maps" class="nav-link" data-scroll-target="#movement-on-contour-maps">Movement on Contour Maps</a></li>
  <li><a href="#convergence-towards-minima" id="toc-convergence-towards-minima" class="nav-link" data-scroll-target="#convergence-towards-minima">Convergence Towards Minima</a></li>
  </ul></li>
  <li><a href="#visualization-of-optimization" id="toc-visualization-of-optimization" class="nav-link" data-scroll-target="#visualization-of-optimization">Visualization of Optimization</a>
  <ul class="collapse">
  <li><a href="#dynamics-of-optimization" id="toc-dynamics-of-optimization" class="nav-link" data-scroll-target="#dynamics-of-optimization">Dynamics of Optimization</a></li>
  <li><a href="#convergence-analysis" id="toc-convergence-analysis" class="nav-link" data-scroll-target="#convergence-analysis">Convergence Analysis</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#momentum-based-gradient-descent" id="toc-momentum-based-gradient-descent" class="nav-link" data-scroll-target="#momentum-based-gradient-descent">Momentum Based Gradient Descent</a>
  <ul class="collapse">
  <li><a href="#introduction-1" id="toc-introduction-1" class="nav-link" data-scroll-target="#introduction-1">Introduction</a></li>
  <li><a href="#understanding-gradient-descent" id="toc-understanding-gradient-descent" class="nav-link" data-scroll-target="#understanding-gradient-descent">Understanding Gradient Descent</a></li>
  <li><a href="#intuition-behind-momentum" id="toc-intuition-behind-momentum" class="nav-link" data-scroll-target="#intuition-behind-momentum">Intuition Behind Momentum</a></li>
  <li><a href="#mathematical-formulation" id="toc-mathematical-formulation" class="nav-link" data-scroll-target="#mathematical-formulation">Mathematical Formulation</a>
  <ul class="collapse">
  <li><a href="#update-rule" id="toc-update-rule" class="nav-link" data-scroll-target="#update-rule">Update Rule</a></li>
  <li><a href="#momentum-coefficient" id="toc-momentum-coefficient" class="nav-link" data-scroll-target="#momentum-coefficient">Momentum Coefficient</a></li>
  </ul></li>
  <li><a href="#implementation" id="toc-implementation" class="nav-link" data-scroll-target="#implementation">Implementation</a>
  <ul class="collapse">
  <li><a href="#algorithm" id="toc-algorithm" class="nav-link" data-scroll-target="#algorithm">Algorithm</a></li>
  <li><a href="#code" id="toc-code" class="nav-link" data-scroll-target="#code">Code</a></li>
  </ul></li>
  <li><a href="#observations-and-issues" id="toc-observations-and-issues" class="nav-link" data-scroll-target="#observations-and-issues">Observations and Issues</a>
  <ul class="collapse">
  <li><a href="#advantages" id="toc-advantages" class="nav-link" data-scroll-target="#advantages">Advantages</a></li>
  <li><a href="#challenges" id="toc-challenges" class="nav-link" data-scroll-target="#challenges">Challenges</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#natural-accelerated-gradient-descent-nag" id="toc-natural-accelerated-gradient-descent-nag" class="nav-link" data-scroll-target="#natural-accelerated-gradient-descent-nag">Natural Accelerated Gradient Descent (NAG)</a>
  <ul class="collapse">
  <li><a href="#introduction-2" id="toc-introduction-2" class="nav-link" data-scroll-target="#introduction-2">Introduction</a></li>
  <li><a href="#nag-concept" id="toc-nag-concept" class="nav-link" data-scroll-target="#nag-concept">NAG Concept</a>
  <ul class="collapse">
  <li><a href="#mathematical-formulation-1" id="toc-mathematical-formulation-1" class="nav-link" data-scroll-target="#mathematical-formulation-1">Mathematical Formulation</a></li>
  <li><a href="#update-mechanism" id="toc-update-mechanism" class="nav-link" data-scroll-target="#update-mechanism">Update Mechanism</a></li>
  </ul></li>
  <li><a href="#visual-illustration" id="toc-visual-illustration" class="nav-link" data-scroll-target="#visual-illustration">Visual Illustration</a>
  <ul class="collapse">
  <li><a href="#optimization-trajectory" id="toc-optimization-trajectory" class="nav-link" data-scroll-target="#optimization-trajectory">Optimization Trajectory</a></li>
  </ul></li>
  <li><a href="#comparison-with-momentum-based-gradient-descent" id="toc-comparison-with-momentum-based-gradient-descent" class="nav-link" data-scroll-target="#comparison-with-momentum-based-gradient-descent">Comparison with Momentum-based Gradient Descent</a>
  <ul class="collapse">
  <li><a href="#oscillation-mitigation" id="toc-oscillation-mitigation" class="nav-link" data-scroll-target="#oscillation-mitigation">Oscillation Mitigation</a></li>
  <li><a href="#convergence-dynamics" id="toc-convergence-dynamics" class="nav-link" data-scroll-target="#convergence-dynamics">Convergence Dynamics</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#stochastic-vs-batch-gradient" id="toc-stochastic-vs-batch-gradient" class="nav-link" data-scroll-target="#stochastic-vs-batch-gradient">Stochastic vs Batch Gradient</a>
  <ul class="collapse">
  <li><a href="#introduction-3" id="toc-introduction-3" class="nav-link" data-scroll-target="#introduction-3">Introduction</a></li>
  <li><a href="#gradient-descent" id="toc-gradient-descent" class="nav-link" data-scroll-target="#gradient-descent">Gradient Descent</a></li>
  <li><a href="#stochastic-gradient-descent-sgd" id="toc-stochastic-gradient-descent-sgd" class="nav-link" data-scroll-target="#stochastic-gradient-descent-sgd">Stochastic Gradient Descent (SGD)</a></li>
  <li><a href="#mini-batch-gradient-descent" id="toc-mini-batch-gradient-descent" class="nav-link" data-scroll-target="#mini-batch-gradient-descent">Mini-Batch Gradient Descent</a></li>
  <li><a href="#comparison-of-algorithms" id="toc-comparison-of-algorithms" class="nav-link" data-scroll-target="#comparison-of-algorithms">Comparison of Algorithms</a>
  <ul class="collapse">
  <li><a href="#performance-characteristics" id="toc-performance-characteristics" class="nav-link" data-scroll-target="#performance-characteristics">Performance Characteristics</a></li>
  <li><a href="#oscillations" id="toc-oscillations" class="nav-link" data-scroll-target="#oscillations">Oscillations</a></li>
  <li><a href="#sensitivity-to-batch-size" id="toc-sensitivity-to-batch-size" class="nav-link" data-scroll-target="#sensitivity-to-batch-size">Sensitivity to Batch Size</a></li>
  </ul></li>
  <li><a href="#adjusting-learning-rate-and-momentum" id="toc-adjusting-learning-rate-and-momentum" class="nav-link" data-scroll-target="#adjusting-learning-rate-and-momentum">Adjusting Learning Rate and Momentum</a>
  <ul class="collapse">
  <li><a href="#learning-rate" id="toc-learning-rate" class="nav-link" data-scroll-target="#learning-rate">Learning Rate</a></li>
  <li><a href="#momentum" id="toc-momentum" class="nav-link" data-scroll-target="#momentum">Momentum</a></li>
  <li><a href="#tuning-parameters" id="toc-tuning-parameters" class="nav-link" data-scroll-target="#tuning-parameters">Tuning Parameters</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#scheduling-learning-rate" id="toc-scheduling-learning-rate" class="nav-link" data-scroll-target="#scheduling-learning-rate">Scheduling learning rate</a>
  <ul class="collapse">
  <li><a href="#adjusting-learning-rate" id="toc-adjusting-learning-rate" class="nav-link" data-scroll-target="#adjusting-learning-rate">Adjusting Learning Rate</a>
  <ul class="collapse">
  <li><a href="#importance-of-learning-rate-adjustment" id="toc-importance-of-learning-rate-adjustment" class="nav-link" data-scroll-target="#importance-of-learning-rate-adjustment">Importance of Learning Rate Adjustment</a></li>
  <li><a href="#strategies-for-setting-learning-rate" id="toc-strategies-for-setting-learning-rate" class="nav-link" data-scroll-target="#strategies-for-setting-learning-rate">Strategies for Setting Learning Rate</a></li>
  <li><a href="#annealing-the-learning-rate" id="toc-annealing-the-learning-rate" class="nav-link" data-scroll-target="#annealing-the-learning-rate">Annealing the Learning Rate</a></li>
  <li><a href="#adjusting-momentum" id="toc-adjusting-momentum" class="nav-link" data-scroll-target="#adjusting-momentum">Adjusting Momentum</a></li>
  <li><a href="#formula-for-momentum-adjustment" id="toc-formula-for-momentum-adjustment" class="nav-link" data-scroll-target="#formula-for-momentum-adjustment">Formula for Momentum Adjustment</a></li>
  </ul></li>
  <li><a href="#line-search" id="toc-line-search" class="nav-link" data-scroll-target="#line-search">Line Search</a>
  <ul class="collapse">
  <li><a href="#process-of-line-search" id="toc-process-of-line-search" class="nav-link" data-scroll-target="#process-of-line-search">Process of Line Search</a></li>
  <li><a href="#benefits-of-line-search" id="toc-benefits-of-line-search" class="nav-link" data-scroll-target="#benefits-of-line-search">Benefits of Line Search</a></li>
  <li><a href="#implementation-considerations" id="toc-implementation-considerations" class="nav-link" data-scroll-target="#implementation-considerations">Implementation Considerations</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../pages/DL/Week01_1.html">Deep Learning</a></li><li class="breadcrumb-item"><a href="../../pages/DL/Week04.html">Week 4</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Variations in Learning</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="understanding-contour-maps" class="level1">
<h1>Understanding Contour Maps</h1>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>In the realm of deep learning, understanding the intricate behavior of functions is crucial for optimizing machine learning models. Contour maps serve as invaluable tools in visualizing and comprehending the complex landscapes of these functions. By representing high-dimensional surfaces in a two-dimensional format, contour maps provide insights into the behavior of loss functions, aiding in the optimization process.</p>
</section>
<section id="construction-of-contour-maps" class="level2">
<h2 class="anchored" data-anchor-id="construction-of-contour-maps">Construction of Contour Maps</h2>
<p>Contour maps are derived from 3D plots of functions, where the function’s output is plotted against two input variables. Consider a function <span class="math inline">\(f(\mathbf{x})\)</span>, where <span class="math inline">\(\mathbf{x}\)</span> represents the input vector. The process of constructing a contour map involves the following steps:</p>
<section id="slicing-the-surface" class="level3">
<h3 class="anchored" data-anchor-id="slicing-the-surface">Slicing the Surface</h3>
<p>Begin by slicing the 3D surface of the function at regular intervals along the z-axis. These slices are parallel to the xy-plane and represent different levels of the function’s output.</p>
</section>
<section id="labeling-the-slices" class="level3">
<h3 class="anchored" data-anchor-id="labeling-the-slices">Labeling the Slices</h3>
<p>Assign labels to each slice to indicate their corresponding z-values. These labels help in understanding the varying levels of the function across different regions of the plot.</p>
</section>
<section id="viewing-from-the-top" class="level3">
<h3 class="anchored" data-anchor-id="viewing-from-the-top">Viewing from the Top</h3>
<p>Observe the slices from a top-down perspective to obtain the contour map. Each contour line on the map represents a specific level of the function, with equidistant intervals between them.</p>
</section>
</section>
<section id="interpreting-contour-maps" class="level2">
<h2 class="anchored" data-anchor-id="interpreting-contour-maps">Interpreting Contour Maps</h2>
<p>Contour maps provide valuable insights into the behavior of functions, particularly in terms of slope and level values. Understanding how to interpret these maps is essential for gaining deeper insights into the optimization process.</p>
<section id="slope-analysis" class="level3">
<h3 class="anchored" data-anchor-id="slope-analysis">Slope Analysis</h3>
<p>The distance between contour lines reflects the slope of the function at different points on the plot. In regions where the slope is gentle, the distance between contour lines is larger. Conversely, in regions with steep slopes, the distance between contour lines is smaller.</p>
</section>
<section id="level-values" class="level3">
<h3 class="anchored" data-anchor-id="level-values">Level Values</h3>
<p>Each contour line represents a constant value of the function. By analyzing the contour map, one can infer the shape and characteristics of the 3D surface. This information is instrumental in understanding the behavior of the function and guiding optimization strategies.</p>
</section>
</section>
<section id="application-to-gradient-descent" class="level2">
<h2 class="anchored" data-anchor-id="application-to-gradient-descent">Application to Gradient Descent</h2>
<p>Gradient descent algorithms aim to minimize the loss function associated with a machine learning model. Contour maps play a crucial role in visualizing and understanding the optimization process.</p>
<section id="movement-on-contour-maps" class="level3">
<h3 class="anchored" data-anchor-id="movement-on-contour-maps">Movement on Contour Maps</h3>
<p>The movement of points on a contour map corresponds to optimization steps taken by gradient descent algorithms. In regions of gentle slope, movement is slower, while in steep regions, movement is rapid.</p>
</section>
<section id="convergence-towards-minima" class="level3">
<h3 class="anchored" data-anchor-id="convergence-towards-minima">Convergence Towards Minima</h3>
<p>As optimization progresses, the contour lines converge towards the minimum point on the surface, indicating convergence of the optimization algorithm. By observing the movement of points on the contour map, one can track the optimization process and assess convergence.</p>
</section>
</section>
<section id="visualization-of-optimization" class="level2">
<h2 class="anchored" data-anchor-id="visualization-of-optimization">Visualization of Optimization</h2>
<p>Visualizing optimization processes on contour maps provides a clear understanding of how machine learning models are optimized.</p>
<section id="dynamics-of-optimization" class="level3">
<h3 class="anchored" data-anchor-id="dynamics-of-optimization">Dynamics of Optimization</h3>
<p>Observing the movement of points on the contour map helps understand the dynamics of optimization. Points move slowly in regions of gentle slope and rapidly in steep regions, reflecting the optimization algorithm’s behavior.</p>
</section>
<section id="convergence-analysis" class="level3">
<h3 class="anchored" data-anchor-id="convergence-analysis">Convergence Analysis</h3>
<p>By tracking the convergence of contour lines towards minima, one can assess the convergence of the optimization algorithm. This visual representation facilitates the analysis of optimization dynamics and aids in fine-tuning machine learning models.</p>
</section>
</section>
</section>
<section id="momentum-based-gradient-descent" class="level1">
<h1>Momentum Based Gradient Descent</h1>
<section id="introduction-1" class="level2">
<h2 class="anchored" data-anchor-id="introduction-1">Introduction</h2>
<p>In the realm of deep learning optimization algorithms, gradient descent stands as a fundamental tool for minimizing loss functions and training neural networks. However, traditional gradient descent methods may exhibit sluggish convergence in regions characterized by shallow slopes. To address this limitation, momentum-based gradient descent emerges as a powerful enhancement, aimed at accelerating convergence and navigating through such flat regions more efficiently.</p>
</section>
<section id="understanding-gradient-descent" class="level2">
<h2 class="anchored" data-anchor-id="understanding-gradient-descent">Understanding Gradient Descent</h2>
<p>At its core, gradient descent is an iterative optimization algorithm employed to minimize a given loss function by adjusting the parameters of a model. It operates by iteratively updating the parameters in the opposite direction of the gradient of the loss function with respect to those parameters. Mathematically, this process can be represented as follows:</p>
<p><span class="math display">\[
\mathbf{W}_{t+1} = \mathbf{W}_{t} - \eta \nabla_{\mathbf{W}} \mathcal{L}(\theta_t)
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\mathbf{W}_t\)</span> represents the parameters (weights) at iteration <span class="math inline">\(t\)</span>.</li>
<li><span class="math inline">\(\eta\)</span> denotes the learning rate.</li>
<li><span class="math inline">\(\nabla_{\mathbf{W}} \mathcal{L}(\theta_t)\)</span> signifies the gradient of the loss function with respect to the parameters at iteration <span class="math inline">\(t\)</span>.</li>
</ul>
</section>
<section id="intuition-behind-momentum" class="level2">
<h2 class="anchored" data-anchor-id="intuition-behind-momentum">Intuition Behind Momentum</h2>
<p>Momentum-based gradient descent introduces the concept of momentum to the optimization process, inspired by physical dynamics. Analogous to a rolling ball gaining momentum as it descends a slope, the algorithm accumulates past gradients to accelerate convergence, especially in regions characterized by gentle slopes.</p>
</section>
<section id="mathematical-formulation" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-formulation">Mathematical Formulation</h2>
<section id="update-rule" class="level3">
<h3 class="anchored" data-anchor-id="update-rule">Update Rule</h3>
<p>The update rule for momentum-based gradient descent incorporates a momentum term, which accounts for the accumulated history of gradients. Mathematically, the update rule can be expressed as follows:</p>
<p><span class="math display">\[
\mathbf{u}_{t+1} = \beta \mathbf{u}_{t} + \eta \nabla_{\mathbf{W}} \mathcal{L}(\theta_t)
\]</span> <span class="math display">\[
\mathbf{W}_{t+1} = \mathbf{W}_{t} - \mathbf{u}_{t+1}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\mathbf{u}_t\)</span> denotes the velocity at iteration <span class="math inline">\(t\)</span>, representing the accumulated history of gradients.</li>
<li><span class="math inline">\(\beta\)</span> signifies the momentum coefficient, typically a value close to 1.</li>
<li><span class="math inline">\(\eta\)</span> remains the learning rate.</li>
<li><span class="math inline">\(\nabla_{\mathbf{W}} \mathcal{L}(\theta_t)\)</span> represents the gradient of the loss function with respect to the parameters at iteration <span class="math inline">\(t\)</span>.</li>
</ul>
</section>
<section id="momentum-coefficient" class="level3">
<h3 class="anchored" data-anchor-id="momentum-coefficient">Momentum Coefficient</h3>
<p>The momentum coefficient (<span class="math inline">\(\beta\)</span>) determines the influence of past gradients on the current update. A higher value of <span class="math inline">\(\beta\)</span> assigns more significance to past gradients, leading to smoother and more stable updates. Conversely, a lower value reduces the impact of past gradients, resulting in a more agile but potentially oscillatory behavior.</p>
</section>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<section id="algorithm" class="level3">
<h3 class="anchored" data-anchor-id="algorithm">Algorithm</h3>
<p>The implementation of momentum-based gradient descent entails the following steps:</p>
<ol type="1">
<li>Initialize the velocity vector <span class="math inline">\(\mathbf{u}\)</span> to zero.</li>
<li>Initialize the parameters (<span class="math inline">\(\mathbf{W}\)</span>) randomly.</li>
<li>Iterate through the training data, computing gradients and updating parameters using the momentum-based update rule.</li>
<li>Repeat until convergence or a predefined number of iterations.</li>
</ol>
</section>
<section id="code" class="level3">
<h3 class="anchored" data-anchor-id="code">Code</h3>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Momentum-based gradient descent algorithm</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>initialize parameters W</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>initialize velocity v <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> each epoch:</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> each training example (x, y):</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>        compute gradient g <span class="op">=</span> ∇_W L(W, x, y)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>        update velocity v <span class="op">=</span> βv <span class="op">+</span> ηg</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        update parameters W <span class="op">=</span> W <span class="op">-</span> v</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="observations-and-issues" class="level2">
<h2 class="anchored" data-anchor-id="observations-and-issues">Observations and Issues</h2>
<section id="advantages" class="level3">
<h3 class="anchored" data-anchor-id="advantages">Advantages</h3>
<ul>
<li>Momentum-based gradient descent accelerates convergence, particularly in regions with shallow gradients.</li>
<li>The algorithm exhibits smoother updates, leading to faster optimization compared to traditional gradient descent.</li>
</ul>
</section>
<section id="challenges" class="level3">
<h3 class="anchored" data-anchor-id="challenges">Challenges</h3>
<ul>
<li><strong>Oscillations</strong>: Momentum may cause the algorithm to overshoot the optimal solution, leading to oscillations around the minima.</li>
<li><strong>Parameter Sensitivity</strong>: The choice of the momentum coefficient (<span class="math inline">\(\beta\)</span>) influences the algorithm’s behavior, requiring careful tuning to achieve optimal performance.</li>
</ul>
</section>
</section>
</section>
<section id="natural-accelerated-gradient-descent-nag" class="level1">
<h1>Natural Accelerated Gradient Descent (NAG)</h1>
<section id="introduction-2" class="level2">
<h2 class="anchored" data-anchor-id="introduction-2">Introduction</h2>
<p>In the realm of optimization techniques for deep learning, Momentum-based Gradient Descent offers enhanced convergence speed over traditional Gradient Descent methods. However, it tends to exhibit oscillations around the minima, hindering its efficiency. To address this limitation, the concept of Nesterov Accelerated Gradient (NAG) Descent emerges as a promising approach. NAG optimizes convergence by incorporating future expectations into the update process, thereby mitigating oscillations and enhancing efficiency.</p>
</section>
<section id="nag-concept" class="level2">
<h2 class="anchored" data-anchor-id="nag-concept">NAG Concept</h2>
<p>NAG fundamentally alters the update mechanism from conventional Gradient Descent approaches by introducing a forward-looking perspective. Instead of relying solely on current gradient information, NAG anticipates future gradients, enabling more informed and precise updates. The core idea behind NAG can be summarized succinctly as “look before you leap,” emphasizing the importance of considering future implications before making significant adjustments.</p>
<section id="mathematical-formulation-1" class="level3">
<h3 class="anchored" data-anchor-id="mathematical-formulation-1">Mathematical Formulation</h3>
<p>To comprehend the inner workings of Nesterov Accelerated Gradient (NAG) descent, let’s delve deeper into its mathematical foundation. At its core, NAG builds upon the momentum-based gradient descent framework, introducing subtle yet impactful modifications to enhance convergence efficiency and stability.</p>
<p>In momentum-based gradient descent, the update rule at iteration <span class="math inline">\(t\)</span> is expressed as:</p>
<p><span class="math display">\[
\mathbf{u}_t = \beta \mathbf{u}_{t-1} - \eta \nabla \mathcal{L}(\theta_t)
\]</span></p>
<p>Here, <span class="math inline">\(\mathbf{u}_t\)</span> represents the velocity at iteration <span class="math inline">\(t\)</span>, <span class="math inline">\(\beta\)</span> denotes the momentum parameter, <span class="math inline">\(\eta\)</span> signifies the learning rate, <span class="math inline">\(\nabla \mathcal{L}(\theta_t)\)</span> denotes the gradient of the loss function with respect to the parameter vector <span class="math inline">\(\theta_t\)</span>.</p>
<p>Incorporating the concept of lookahead, NAG introduces a refinement to the update rule as follows:</p>
<p><span class="math display">\[
\mathbf{u}_t = \beta \mathbf{u}_{t-1} - \eta \nabla \mathcal{L}(\theta_t - \beta \mathbf{u}_{t-1})
\]</span></p>
<p>Here, <span class="math inline">\(\theta_t - \beta \mathbf{u}_{t-1}\)</span> represents the partially updated parameter vector. By computing the gradient at this partially updated point, NAG anticipates the influence of momentum on the parameter update, thereby making adjustments that align more closely with the desired direction of descent.</p>
<p>This subtle modification imbues NAG with the ability to preemptively adjust its trajectory based on future expectations, effectively mitigating the oscillatory behavior commonly observed in momentum-based approaches. Through this nuanced approach, NAG achieves enhanced convergence efficiency and stability, making it a compelling optimization algorithm for deep learning tasks.</p>
</section>
<section id="update-mechanism" class="level3">
<h3 class="anchored" data-anchor-id="update-mechanism">Update Mechanism</h3>
<ol type="1">
<li><strong>Partial Update</strong>: Initially, NAG performs a partial update based on historical information, steering the optimization process in a specific direction.</li>
<li><strong>Gradient Computation</strong>: Subsequently, the gradient is computed at the partially updated point, offering insights into the directionality of future adjustments.</li>
<li><strong>Final Adjustment</strong>: The final update is then determined by incorporating the computed gradient, aligning the optimization trajectory with anticipated improvements.</li>
</ol>
</section>
</section>
<section id="visual-illustration" class="level2">
<h2 class="anchored" data-anchor-id="visual-illustration">Visual Illustration</h2>
<p>To elucidate the operational dynamics of NAG, let’s visualize its behavior in a hypothetical loss landscape scenario. Consider a two-dimensional plot with the weight axis and the corresponding loss values. Initially, the optimization process commences at a specific weight point, characterized by a corresponding loss value.</p>
<section id="optimization-trajectory" class="level3">
<h3 class="anchored" data-anchor-id="optimization-trajectory">Optimization Trajectory</h3>
<ol type="1">
<li><strong>Partial Update</strong>: NAG initiates the optimization by performing a partial update, guided by historical information accumulated during previous iterations.</li>
<li><strong>Gradient Evaluation</strong>: Following the partial update, the gradient is evaluated at the adjusted weight point, providing insights into the prospective optimization direction.</li>
<li><strong>Refined Update</strong>: Leveraging the computed gradient, NAG refines the optimization trajectory, aligning it with anticipated improvements and mitigating the risk of overshooting minima.</li>
</ol>
</section>
</section>
<section id="comparison-with-momentum-based-gradient-descent" class="level2">
<h2 class="anchored" data-anchor-id="comparison-with-momentum-based-gradient-descent">Comparison with Momentum-based Gradient Descent</h2>
<p>To appreciate the efficacy of NAG relative to Momentum-based Gradient Descent, let’s juxtapose their operational characteristics and optimization behaviors.</p>
<section id="oscillation-mitigation" class="level3">
<h3 class="anchored" data-anchor-id="oscillation-mitigation">Oscillation Mitigation</h3>
<ol type="1">
<li><strong>NAG</strong>: By incorporating future expectations into the update process, NAG swiftly corrects its trajectory, minimizing oscillations and promoting convergence efficiency.</li>
<li><strong>Momentum-based Gradient Descent</strong>: In contrast, Momentum-based methods may exhibit delayed response to optimization errors, leading to prolonged oscillations and suboptimal convergence trajectories.</li>
</ol>
</section>
<section id="convergence-dynamics" class="level3">
<h3 class="anchored" data-anchor-id="convergence-dynamics">Convergence Dynamics</h3>
<ol type="1">
<li><strong>NAG</strong>: The forward-looking approach of NAG facilitates proactive optimization adjustments, resulting in smoother convergence trajectories and enhanced convergence rates.</li>
<li><strong>Momentum-based Gradient Descent</strong>: While effective in accelerating convergence, Momentum-based methods may exhibit erratic optimization trajectories, characterized by frequent oscillations and suboptimal convergence rates.</li>
</ol>
</section>
</section>
</section>
<section id="stochastic-vs-batch-gradient" class="level1">
<h1>Stochastic vs Batch Gradient</h1>
<section id="introduction-3" class="level2">
<h2 class="anchored" data-anchor-id="introduction-3">Introduction</h2>
<p>In deep learning, optimization algorithms play a crucial role in training neural networks efficiently. These algorithms aim to minimize a given loss function by updating the model parameters iteratively. In this discussion, we delve into the concepts of gradient descent, stochastic gradient descent (SGD), mini-batch gradient descent, and their variants. Additionally, we explore the adjustments of learning rate and momentum to enhance the optimization process.</p>
</section>
<section id="gradient-descent" class="level2">
<h2 class="anchored" data-anchor-id="gradient-descent">Gradient Descent</h2>
<p>Gradient descent is a fundamental optimization algorithm used to minimize the loss function of a neural network. At each iteration, it computes the gradient of the loss function with respect to the model parameters and updates the parameters in the direction of the negative gradient. Mathematically, the update rule for the parameters <span class="math inline">\(\theta\)</span> at iteration <span class="math inline">\(t\)</span> can be expressed as:</p>
<p><span class="math display">\[
\theta_{t+1} = \theta_t - \eta \nabla \mathcal{L}(\theta_t)
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\eta\)</span> is the learning rate, controlling the step size of the update.</li>
<li><span class="math inline">\(\nabla \mathcal{L}(\theta_t)\)</span> is the gradient of the loss function <span class="math inline">\(\mathcal{L}\)</span> with respect to the parameters <span class="math inline">\(\theta_t\)</span>.</li>
</ul>
</section>
<section id="stochastic-gradient-descent-sgd" class="level2">
<h2 class="anchored" data-anchor-id="stochastic-gradient-descent-sgd">Stochastic Gradient Descent (SGD)</h2>
<p>Stochastic gradient descent (SGD) is an extension of gradient descent where instead of computing the gradient using the entire dataset, it computes the gradient using only one randomly selected data point at each iteration. This introduces stochasticity into the optimization process and accelerates convergence, especially for large datasets. The update rule for SGD can be expressed as:</p>
<p><span class="math display">\[
\theta_{t+1} = \theta_t - \eta \nabla \mathcal{L}_i(\theta_t)
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\mathcal{L}_i(\theta_t)\)</span> is the loss function computed on a single randomly selected data point.</li>
</ul>
</section>
<section id="mini-batch-gradient-descent" class="level2">
<h2 class="anchored" data-anchor-id="mini-batch-gradient-descent">Mini-Batch Gradient Descent</h2>
<p>Mini-batch gradient descent is a compromise between batch gradient descent and SGD. Instead of using the entire dataset or just one data point, mini-batch gradient descent computes the gradient using a small random subset of the data called a mini-batch. This approach combines the efficiency of SGD with the stability of batch gradient descent. The update rule for mini-batch gradient descent can be expressed as:</p>
<p><span class="math display">\[
\theta_{t+1} = \theta_t - \eta \nabla \mathcal{L}_B(\theta_t)
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\mathcal{L}_B(\theta_t)\)</span> is the loss function computed on a mini-batch of data.</li>
</ul>
</section>
<section id="comparison-of-algorithms" class="level2">
<h2 class="anchored" data-anchor-id="comparison-of-algorithms">Comparison of Algorithms</h2>
<section id="performance-characteristics" class="level3">
<h3 class="anchored" data-anchor-id="performance-characteristics">Performance Characteristics</h3>
<ul>
<li><strong>Batch Gradient Descent</strong>: Computes the gradient using the entire dataset. Provides accurate updates but can be slow for large datasets.</li>
<li><strong>Stochastic Gradient Descent (SGD)</strong>: Computes the gradient using one data point. Faster convergence but noisy updates.</li>
<li><strong>Mini-Batch Gradient Descent</strong>: Computes the gradient using a mini-batch of data. Balances between accuracy and efficiency.</li>
</ul>
</section>
<section id="oscillations" class="level3">
<h3 class="anchored" data-anchor-id="oscillations">Oscillations</h3>
<ul>
<li><strong>SGD</strong>: Exhibits more oscillations due to its stochastic nature.</li>
<li><strong>Mini-Batch Gradient Descent</strong>: Strikes a balance between smoothness and speed, reducing oscillations compared to SGD.</li>
</ul>
</section>
<section id="sensitivity-to-batch-size" class="level3">
<h3 class="anchored" data-anchor-id="sensitivity-to-batch-size">Sensitivity to Batch Size</h3>
<ul>
<li>The choice of batch size in mini-batch gradient descent impacts the training dynamics.</li>
<li>Larger batch sizes may lead to smoother convergence but require more memory and computational resources.</li>
</ul>
</section>
</section>
<section id="adjusting-learning-rate-and-momentum" class="level2">
<h2 class="anchored" data-anchor-id="adjusting-learning-rate-and-momentum">Adjusting Learning Rate and Momentum</h2>
<section id="learning-rate" class="level3">
<h3 class="anchored" data-anchor-id="learning-rate">Learning Rate</h3>
<p>The learning rate (<span class="math inline">\(\eta\)</span>) controls the step size of parameter updates in gradient-based optimization algorithms. It is a hyperparameter that needs to be carefully tuned for optimal performance.</p>
<ul>
<li><strong>Effect on Convergence</strong>: A higher learning rate may lead to faster convergence but risks overshooting the minimum.</li>
<li><strong>Effect on Stability</strong>: A lower learning rate may result in slower convergence but offers more stability during training.</li>
</ul>
</section>
<section id="momentum" class="level3">
<h3 class="anchored" data-anchor-id="momentum">Momentum</h3>
<p>Momentum is a technique used to accelerate convergence by damping oscillations and navigating through saddle points more effectively. It introduces a velocity term to the parameter updates, which helps in maintaining directionality. Mathematically, the update rule with momentum can be expressed as:</p>
<p><span class="math display">\[
\mathbf{u}_t = \gamma \mathbf{u}_{t-1} + \eta \nabla \mathcal{L}(\theta_t)
\]</span> <span class="math display">\[
\theta_{t+1} = \theta_t - \mathbf{u}_t
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\gamma\)</span> is the momentum coefficient.</li>
<li><span class="math inline">\(\mathbf{u}_t\)</span> is the velocity at iteration <span class="math inline">\(t\)</span>.</li>
<li><span class="math inline">\(\eta \nabla \mathcal{L}(\theta_t)\)</span> is the gradient descent update.</li>
</ul>
</section>
<section id="tuning-parameters" class="level3">
<h3 class="anchored" data-anchor-id="tuning-parameters">Tuning Parameters</h3>
<ul>
<li><strong>Learning Rate</strong>: Experimentation and analysis of the training dynamics help in selecting an appropriate learning rate. Techniques such as learning rate schedules and adaptive learning rate methods can be employed.</li>
<li><strong>Momentum</strong>: The momentum coefficient (<span class="math inline">\(\gamma\)</span>) needs to be tuned based on the characteristics of the optimization problem and the architecture of the neural network.</li>
</ul>
</section>
</section>
</section>
<section id="scheduling-learning-rate" class="level1">
<h1>Scheduling learning rate</h1>
<p>In deep learning, optimization techniques play a crucial role in training neural networks effectively. These techniques involve adjusting parameters such as learning rates and momentum to improve convergence and performance. This chapter discusses various optimization methods, including adjusting learning rates and momentum, as well as line search, in detail.</p>
<section id="adjusting-learning-rate" class="level2">
<h2 class="anchored" data-anchor-id="adjusting-learning-rate">Adjusting Learning Rate</h2>
<p>The learning rate (<span class="math inline">\(\eta\)</span>) is a key hyperparameter that determines the step size of parameter updates during training. A suitable learning rate is essential for efficient convergence of the optimization algorithm. However, choosing an appropriate learning rate can be challenging and may require experimentation.</p>
<section id="importance-of-learning-rate-adjustment" class="level3">
<h3 class="anchored" data-anchor-id="importance-of-learning-rate-adjustment">Importance of Learning Rate Adjustment</h3>
<p>The learning rate influences the speed and stability of convergence during training. A high learning rate can lead to rapid progress but may result in overshooting or oscillations around the minimum. Conversely, a low learning rate may slow down convergence or cause the algorithm to get stuck in local minima.</p>
</section>
<section id="strategies-for-setting-learning-rate" class="level3">
<h3 class="anchored" data-anchor-id="strategies-for-setting-learning-rate">Strategies for Setting Learning Rate</h3>
<ol type="1">
<li><strong>Experimentation on a Logarithmic Scale</strong>:
<ul>
<li>Experiment with different learning rates on a logarithmic scale (e.g., (0.001), (0.01), (0.1)).</li>
<li>Observe the behavior of the loss function for each learning rate during a few epochs of training.</li>
<li>Choose a learning rate that results in a smooth decrease in the loss.</li>
</ul></li>
<li><strong>Annealing the Learning Rate</strong>:
<ul>
<li>Reduce the learning rate as training progresses to prevent overshooting.</li>
<li>Use techniques such as step decay, where the learning rate is decreased after a fixed number of epochs.</li>
<li>Monitor the validation loss and reduce the learning rate if the validation loss increases.</li>
</ul></li>
</ol>
</section>
<section id="annealing-the-learning-rate" class="level3">
<h3 class="anchored" data-anchor-id="annealing-the-learning-rate">Annealing the Learning Rate</h3>
<p>Annealing the learning rate involves gradually decreasing the learning rate as training progresses. This approach helps stabilize training and prevent overshooting of the minimum. One common method for annealing the learning rate is <strong>exponential decay</strong>.</p>
<section id="exponential-decay" class="level4">
<h4 class="anchored" data-anchor-id="exponential-decay">Exponential Decay</h4>
<p>In exponential decay, the learning rate (<span class="math inline">\(\eta_t\)</span>) at iteration <span class="math inline">\(t\)</span> is given by:</p>
<p><span class="math display">\[ \eta_t = \frac{\eta_0}{(1 + k \cdot t)} \]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\eta_0\)</span>: Initial learning rate.</li>
<li><span class="math inline">\(t\)</span>: Current iteration.</li>
<li><span class="math inline">\(k\)</span>: Decay rate hyperparameter.</li>
</ul>
<p>Exponential decay gradually reduces the learning rate over time, allowing the optimization algorithm to make smaller updates as training progresses. However, choosing an appropriate decay rate (<span class="math inline">\(k\)</span>) is crucial and may require experimentation.</p>
</section>
</section>
<section id="adjusting-momentum" class="level3">
<h3 class="anchored" data-anchor-id="adjusting-momentum">Adjusting Momentum</h3>
<p>Momentum is another important hyperparameter in optimization algorithms, especially in stochastic gradient descent variants. Momentum helps accelerate convergence by adding a fraction of the previous update to the current update. Adjusting momentum involves determining the optimal value for the momentum parameter (<span class="math inline">\(\beta\)</span>).</p>
<section id="momentum-adjustment-method" class="level4">
<h4 class="anchored" data-anchor-id="momentum-adjustment-method">Momentum Adjustment Method</h4>
<p>One method for adjusting momentum involves using a formula that gradually increases the momentum as training progresses. This method ensures that the optimization algorithm relies more on historical updates as it approaches the minimum.</p>
</section>
</section>
<section id="formula-for-momentum-adjustment" class="level3">
<h3 class="anchored" data-anchor-id="formula-for-momentum-adjustment">Formula for Momentum Adjustment</h3>
<p>The momentum (<span class="math inline">\(\beta\)</span>) at iteration <span class="math inline">\(t\)</span> is given by:</p>
<p><span class="math display">\[ \beta_t = \min \left(0.5, \beta_{\text{max}} \right)^{\log(t+1)} \]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(t\)</span>: Current iteration.</li>
<li><span class="math inline">\(\beta_{\text{max}}\)</span>: Maximum momentum value.</li>
</ul>
<p>This formula gradually increases the momentum (<span class="math inline">\(\beta\)</span>) as <span class="math inline">\(t\)</span> increases, emphasizing historical updates over current updates. By adjusting momentum dynamically, the optimization algorithm can effectively navigate complex optimization landscapes and converge faster.</p>
</section>
</section>
<section id="line-search" class="level2">
<h2 class="anchored" data-anchor-id="line-search">Line Search</h2>
<p>Line search is a technique used to adaptively adjust the learning rate during optimization by evaluating multiple learning rates at each iteration. This approach helps overcome the limitations of fixed learning rates by dynamically selecting the most suitable learning rate based on the local curvature of the loss function.</p>
<section id="process-of-line-search" class="level3">
<h3 class="anchored" data-anchor-id="process-of-line-search">Process of Line Search</h3>
<ol type="1">
<li><strong>Compute Derivative</strong>: Calculate the derivative of the loss function with respect to the parameters.</li>
<li><strong>Try Different Learning Rates</strong>: Evaluate the loss function for multiple learning rates to obtain updated parameter values.</li>
<li><strong>Select Optimal Learning Rate</strong>: Choose the learning rate that results in the minimum loss as the next iteration’s learning rate.</li>
</ol>
</section>
<section id="benefits-of-line-search" class="level3">
<h3 class="anchored" data-anchor-id="benefits-of-line-search">Benefits of Line Search</h3>
<ul>
<li><strong>Adaptive Learning Rate</strong>: Line search adaptively adjusts the learning rate based on the local curvature of the loss function, allowing for faster convergence and improved stability.</li>
<li><strong>Avoids Oscillations</strong>: By dynamically selecting the most suitable learning rate, line search helps prevent oscillations and overshooting during optimization.</li>
</ul>
</section>
<section id="implementation-considerations" class="level3">
<h3 class="anchored" data-anchor-id="implementation-considerations">Implementation Considerations</h3>
<ul>
<li><strong>Computational Complexity</strong>: Line search involves evaluating the loss function for multiple learning rates, which increases computational overhead.</li>
<li><strong>Convergence Speed</strong>: Despite the additional computational cost, line search often leads to faster convergence compared to fixed learning rates.</li>
</ul>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>